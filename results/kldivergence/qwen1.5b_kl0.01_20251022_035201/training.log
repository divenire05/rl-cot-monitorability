/workspace/miniconda/envs/verl/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
WARNING:2025-10-22 03:52:05,833:Skipping import of cpp extensions due to incompatible torch version 2.6.0+cu124 for torchao version 0.14.0         Please see GitHub issue #2919 for more info
/workspace/miniconda/envs/verl/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
ray init kwargs: {'num_cpus': None, 'runtime_env': {'env_vars': {'TOKENIZERS_PARALLELISM': 'true', 'NCCL_DEBUG': 'WARN', 'VLLM_LOGGING_LEVEL': 'WARN', 'VLLM_ALLOW_RUNTIME_LORA_UPDATING': 'true', 'CUDA_DEVICE_MAX_CONNECTIONS': '1', 'NCCL_CUMEM_ENABLE': '0'}, 'working_dir': None}}
2025-10-22 03:52:11,628	WARNING utils.py:458 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2025-10-22 03:52:11,628	WARNING utils.py:470 -- Ray currently does not support initializing Ray with fractional cpus. Your num_cpus will be truncated from 44.2 to 44.
2025-10-22 03:52:11,816	INFO worker.py:2004 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/workspace/miniconda/envs/verl/lib/python3.10/site-packages/ray/_private/worker.py:2052: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(pid=6616)[0m /workspace/miniconda/envs/verl/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
[36m(pid=6616)[0m   import pynvml  # type: ignore[import]
[36m(pid=6616)[0m WARNING:2025-10-22 03:52:16,552:Skipping import of cpp extensions due to incompatible torch version 2.6.0+cu124 for torchao version 0.14.0         Please see GitHub issue #2919 for more info
[36m(pid=6616)[0m /workspace/miniconda/envs/verl/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
[36m(pid=6616)[0m   import pynvml  # type: ignore[import]
[36m(TaskRunner pid=6616)[0m TaskRunner hostname: fe9213430a00, PID: 6616
[36m(TaskRunner pid=6616)[0m {'actor_rollout_ref': {'actor': {'_target_': 'verl.workers.config.FSDPActorConfig',
[36m(TaskRunner pid=6616)[0m                                  'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',
[36m(TaskRunner pid=6616)[0m                                                 'async_save': False,
[36m(TaskRunner pid=6616)[0m                                                 'load_contents': ['model',
[36m(TaskRunner pid=6616)[0m                                                                   'optimizer',
[36m(TaskRunner pid=6616)[0m                                                                   'extra'],
[36m(TaskRunner pid=6616)[0m                                                 'save_contents': ['model',
[36m(TaskRunner pid=6616)[0m                                                                   'optimizer',
[36m(TaskRunner pid=6616)[0m                                                                   'extra']},
[36m(TaskRunner pid=6616)[0m                                  'clip_ratio': 0.2,
[36m(TaskRunner pid=6616)[0m                                  'clip_ratio_c': 3.0,
[36m(TaskRunner pid=6616)[0m                                  'clip_ratio_high': 0.2,
[36m(TaskRunner pid=6616)[0m                                  'clip_ratio_low': 0.2,
[36m(TaskRunner pid=6616)[0m                                  'entropy_checkpointing': False,
[36m(TaskRunner pid=6616)[0m                                  'entropy_coeff': 0,
[36m(TaskRunner pid=6616)[0m                                  'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=6616)[0m                                  'freeze_vision_tower': False,
[36m(TaskRunner pid=6616)[0m                                  'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=6616)[0m                                                  'entropy_checkpointing': False,
[36m(TaskRunner pid=6616)[0m                                                  'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=6616)[0m                                                  'forward_only': False,
[36m(TaskRunner pid=6616)[0m                                                  'forward_prefetch': False,
[36m(TaskRunner pid=6616)[0m                                                  'fsdp_size': -1,
[36m(TaskRunner pid=6616)[0m                                                  'model_dtype': 'fp32',
[36m(TaskRunner pid=6616)[0m                                                  'offload_policy': False,
[36m(TaskRunner pid=6616)[0m                                                  'optimizer_offload': False,
[36m(TaskRunner pid=6616)[0m                                                  'param_offload': False,
[36m(TaskRunner pid=6616)[0m                                                  'reshard_after_forward': True,
[36m(TaskRunner pid=6616)[0m                                                  'strategy': 'fsdp',
[36m(TaskRunner pid=6616)[0m                                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m                                                  'use_orig_params': False,
[36m(TaskRunner pid=6616)[0m                                                  'use_torch_compile': True,
[36m(TaskRunner pid=6616)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=6616)[0m                                  'grad_clip': 1.0,
[36m(TaskRunner pid=6616)[0m                                  'kl_loss_coef': 0.001,
[36m(TaskRunner pid=6616)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(TaskRunner pid=6616)[0m                                  'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=6616)[0m                                  'optim': {'_target_': 'verl.workers.config.FSDPOptimizerConfig',
[36m(TaskRunner pid=6616)[0m                                            'betas': [0.9, 0.999],
[36m(TaskRunner pid=6616)[0m                                            'clip_grad': 1.0,
[36m(TaskRunner pid=6616)[0m                                            'lr': 0.0001,
[36m(TaskRunner pid=6616)[0m                                            'lr_scheduler_type': 'constant',
[36m(TaskRunner pid=6616)[0m                                            'lr_warmup_steps': -1,
[36m(TaskRunner pid=6616)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=6616)[0m                                            'min_lr_ratio': 0.0,
[36m(TaskRunner pid=6616)[0m                                            'num_cycles': 0.5,
[36m(TaskRunner pid=6616)[0m                                            'total_training_steps': -1,
[36m(TaskRunner pid=6616)[0m                                            'warmup_style': None,
[36m(TaskRunner pid=6616)[0m                                            'weight_decay': 0.01},
[36m(TaskRunner pid=6616)[0m                                  'policy_loss': {'_target_': 'verl.workers.config.PolicyLossConfig',
[36m(TaskRunner pid=6616)[0m                                                  'clip_cov_lb': 1.0,
[36m(TaskRunner pid=6616)[0m                                                  'clip_cov_ratio': 0.0002,
[36m(TaskRunner pid=6616)[0m                                                  'clip_cov_ub': 5.0,
[36m(TaskRunner pid=6616)[0m                                                  'kl_cov_ratio': 0.0002,
[36m(TaskRunner pid=6616)[0m                                                  'loss_mode': 'vanilla',
[36m(TaskRunner pid=6616)[0m                                                  'ppo_kl_coef': 0.1},
[36m(TaskRunner pid=6616)[0m                                  'ppo_epochs': 1,
[36m(TaskRunner pid=6616)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=6616)[0m                                  'ppo_micro_batch_size': None,
[36m(TaskRunner pid=6616)[0m                                  'ppo_micro_batch_size_per_gpu': 8,
[36m(TaskRunner pid=6616)[0m                                  'ppo_mini_batch_size': 256,
[36m(TaskRunner pid=6616)[0m                                  'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=6616)[0m                                               'all_ranks': False,
[36m(TaskRunner pid=6616)[0m                                               'enable': False,
[36m(TaskRunner pid=6616)[0m                                               'ranks': [],
[36m(TaskRunner pid=6616)[0m                                               'save_path': 'outputs/profile',
[36m(TaskRunner pid=6616)[0m                                               'tool': None,
[36m(TaskRunner pid=6616)[0m                                               'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                       'analysis': True,
[36m(TaskRunner pid=6616)[0m                                                                       'contents': [],
[36m(TaskRunner pid=6616)[0m                                                                       'discrete': False,
[36m(TaskRunner pid=6616)[0m                                                                       'level': 'level1'},
[36m(TaskRunner pid=6616)[0m                                                               'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                        'discrete': False},
[36m(TaskRunner pid=6616)[0m                                                               'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                         'step_end': None,
[36m(TaskRunner pid=6616)[0m                                                                         'step_start': 0},
[36m(TaskRunner pid=6616)[0m                                                               'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                                'stack_depth': 32,
[36m(TaskRunner pid=6616)[0m                                                                                'trace_alloc_max_entries': 100000}}},
[36m(TaskRunner pid=6616)[0m                                  'shuffle': False,
[36m(TaskRunner pid=6616)[0m                                  'strategy': 'fsdp',
[36m(TaskRunner pid=6616)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m                                  'use_dynamic_bsz': False,
[36m(TaskRunner pid=6616)[0m                                  'use_fused_kernels': False,
[36m(TaskRunner pid=6616)[0m                                  'use_kl_loss': False,
[36m(TaskRunner pid=6616)[0m                                  'use_remove_padding': False,
[36m(TaskRunner pid=6616)[0m                                  'use_torch_compile': True},
[36m(TaskRunner pid=6616)[0m                        'hybrid_engine': True,
[36m(TaskRunner pid=6616)[0m                        'model': {'_target_': 'verl.workers.config.HFModelConfig',
[36m(TaskRunner pid=6616)[0m                                  'custom_chat_template': None,
[36m(TaskRunner pid=6616)[0m                                  'enable_activation_offload': False,
[36m(TaskRunner pid=6616)[0m                                  'enable_gradient_checkpointing': False,
[36m(TaskRunner pid=6616)[0m                                  'exclude_modules': None,
[36m(TaskRunner pid=6616)[0m                                  'external_lib': None,
[36m(TaskRunner pid=6616)[0m                                  'fused_kernel_options': {'impl_backend': 'torch'},
[36m(TaskRunner pid=6616)[0m                                  'hf_config_path': None,
[36m(TaskRunner pid=6616)[0m                                  'lora_alpha': 32,
[36m(TaskRunner pid=6616)[0m                                  'lora_rank': 16,
[36m(TaskRunner pid=6616)[0m                                  'override_config': {},
[36m(TaskRunner pid=6616)[0m                                  'path': 'Qwen/Qwen2.5-1.5B-Instruct',
[36m(TaskRunner pid=6616)[0m                                  'target_modules': 'all-linear',
[36m(TaskRunner pid=6616)[0m                                  'tokenizer_path': None,
[36m(TaskRunner pid=6616)[0m                                  'trust_remote_code': False,
[36m(TaskRunner pid=6616)[0m                                  'use_fused_kernels': False,
[36m(TaskRunner pid=6616)[0m                                  'use_liger': False,
[36m(TaskRunner pid=6616)[0m                                  'use_remove_padding': False,
[36m(TaskRunner pid=6616)[0m                                  'use_shm': False},
[36m(TaskRunner pid=6616)[0m                        'nccl_timeout': 600,
[36m(TaskRunner pid=6616)[0m                        'ref': {'entropy_checkpointing': False,
[36m(TaskRunner pid=6616)[0m                                'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=6616)[0m                                'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=6616)[0m                                                'entropy_checkpointing': False,
[36m(TaskRunner pid=6616)[0m                                                'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=6616)[0m                                                'forward_only': False,
[36m(TaskRunner pid=6616)[0m                                                'forward_prefetch': False,
[36m(TaskRunner pid=6616)[0m                                                'fsdp_size': -1,
[36m(TaskRunner pid=6616)[0m                                                'model_dtype': 'fp32',
[36m(TaskRunner pid=6616)[0m                                                'offload_policy': False,
[36m(TaskRunner pid=6616)[0m                                                'optimizer_offload': False,
[36m(TaskRunner pid=6616)[0m                                                'param_offload': False,
[36m(TaskRunner pid=6616)[0m                                                'reshard_after_forward': True,
[36m(TaskRunner pid=6616)[0m                                                'strategy': 'fsdp',
[36m(TaskRunner pid=6616)[0m                                                'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m                                                'use_orig_params': False,
[36m(TaskRunner pid=6616)[0m                                                'use_torch_compile': True,
[36m(TaskRunner pid=6616)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=6616)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=6616)[0m                                'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=6616)[0m                                'log_prob_micro_batch_size_per_gpu': 8,
[36m(TaskRunner pid=6616)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=6616)[0m                                'model': None,
[36m(TaskRunner pid=6616)[0m                                'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=6616)[0m                                             'all_ranks': False,
[36m(TaskRunner pid=6616)[0m                                             'enable': False,
[36m(TaskRunner pid=6616)[0m                                             'ranks': [],
[36m(TaskRunner pid=6616)[0m                                             'save_path': 'outputs/profile',
[36m(TaskRunner pid=6616)[0m                                             'tool': None,
[36m(TaskRunner pid=6616)[0m                                             'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                     'analysis': True,
[36m(TaskRunner pid=6616)[0m                                                                     'contents': [],
[36m(TaskRunner pid=6616)[0m                                                                     'discrete': False,
[36m(TaskRunner pid=6616)[0m                                                                     'level': 'level1'},
[36m(TaskRunner pid=6616)[0m                                                             'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                      'discrete': False},
[36m(TaskRunner pid=6616)[0m                                                             'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                       'step_end': None,
[36m(TaskRunner pid=6616)[0m                                                                       'step_start': 0},
[36m(TaskRunner pid=6616)[0m                                                             'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                              'stack_depth': 32,
[36m(TaskRunner pid=6616)[0m                                                                              'trace_alloc_max_entries': 100000}}},
[36m(TaskRunner pid=6616)[0m                                'strategy': 'fsdp',
[36m(TaskRunner pid=6616)[0m                                'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m                                'use_torch_compile': True},
[36m(TaskRunner pid=6616)[0m                        'rollout': {'_target_': 'verl.workers.config.RolloutConfig',
[36m(TaskRunner pid=6616)[0m                                    'agent': {'_target_': 'verl.workers.config.AgentLoopConfig',
[36m(TaskRunner pid=6616)[0m                                              'agent_loop_config_path': None,
[36m(TaskRunner pid=6616)[0m                                              'custom_async_server': {'_target_': 'verl.workers.config.CustomAsyncServerConfig',
[36m(TaskRunner pid=6616)[0m                                                                      'name': None,
[36m(TaskRunner pid=6616)[0m                                                                      'path': None},
[36m(TaskRunner pid=6616)[0m                                              'default_agent_loop': 'single_turn_agent',
[36m(TaskRunner pid=6616)[0m                                              'num_workers': 8},
[36m(TaskRunner pid=6616)[0m                                    'calculate_log_probs': False,
[36m(TaskRunner pid=6616)[0m                                    'cudagraph_capture_sizes': None,
[36m(TaskRunner pid=6616)[0m                                    'data_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m                                    'disable_log_stats': True,
[36m(TaskRunner pid=6616)[0m                                    'do_sample': True,
[36m(TaskRunner pid=6616)[0m                                    'dtype': 'bfloat16',
[36m(TaskRunner pid=6616)[0m                                    'enable_chunked_prefill': True,
[36m(TaskRunner pid=6616)[0m                                    'enable_prefix_caching': True,
[36m(TaskRunner pid=6616)[0m                                    'enforce_eager': False,
[36m(TaskRunner pid=6616)[0m                                    'engine_kwargs': {'sglang': {}, 'vllm': {}},
[36m(TaskRunner pid=6616)[0m                                    'expert_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m                                    'free_cache_engine': True,
[36m(TaskRunner pid=6616)[0m                                    'gpu_memory_utilization': 0.5,
[36m(TaskRunner pid=6616)[0m                                    'ignore_eos': False,
[36m(TaskRunner pid=6616)[0m                                    'layered_summon': False,
[36m(TaskRunner pid=6616)[0m                                    'load_format': 'dummy',
[36m(TaskRunner pid=6616)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=6616)[0m                                    'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=6616)[0m                                    'log_prob_micro_batch_size_per_gpu': 16,
[36m(TaskRunner pid=6616)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=6616)[0m                                    'max_model_len': None,
[36m(TaskRunner pid=6616)[0m                                    'max_num_batched_tokens': 8192,
[36m(TaskRunner pid=6616)[0m                                    'max_num_seqs': 1024,
[36m(TaskRunner pid=6616)[0m                                    'mode': 'sync',
[36m(TaskRunner pid=6616)[0m                                    'multi_stage_wake_up': False,
[36m(TaskRunner pid=6616)[0m                                    'multi_turn': {'_target_': 'verl.workers.config.MultiTurnConfig',
[36m(TaskRunner pid=6616)[0m                                                   'enable': False,
[36m(TaskRunner pid=6616)[0m                                                   'format': 'hermes',
[36m(TaskRunner pid=6616)[0m                                                   'interaction_config_path': None,
[36m(TaskRunner pid=6616)[0m                                                   'max_assistant_turns': None,
[36m(TaskRunner pid=6616)[0m                                                   'max_parallel_calls': 1,
[36m(TaskRunner pid=6616)[0m                                                   'max_tool_response_length': 256,
[36m(TaskRunner pid=6616)[0m                                                   'max_user_turns': None,
[36m(TaskRunner pid=6616)[0m                                                   'num_repeat_rollouts': None,
[36m(TaskRunner pid=6616)[0m                                                   'tokenization_sanity_check_mode': 'strict',
[36m(TaskRunner pid=6616)[0m                                                   'tool_config_path': None,
[36m(TaskRunner pid=6616)[0m                                                   'tool_response_truncate_side': 'middle',
[36m(TaskRunner pid=6616)[0m                                                   'use_inference_chat_template': False},
[36m(TaskRunner pid=6616)[0m                                    'n': 1,
[36m(TaskRunner pid=6616)[0m                                    'name': 'vllm',
[36m(TaskRunner pid=6616)[0m                                    'over_sample_rate': 0,
[36m(TaskRunner pid=6616)[0m                                    'pipeline_model_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m                                    'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=6616)[0m                                                 'all_ranks': False,
[36m(TaskRunner pid=6616)[0m                                                 'enable': False,
[36m(TaskRunner pid=6616)[0m                                                 'ranks': [],
[36m(TaskRunner pid=6616)[0m                                                 'save_path': 'outputs/profile',
[36m(TaskRunner pid=6616)[0m                                                 'tool': None,
[36m(TaskRunner pid=6616)[0m                                                 'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                         'analysis': True,
[36m(TaskRunner pid=6616)[0m                                                                         'contents': [],
[36m(TaskRunner pid=6616)[0m                                                                         'discrete': False,
[36m(TaskRunner pid=6616)[0m                                                                         'level': 'level1'},
[36m(TaskRunner pid=6616)[0m                                                                 'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                          'discrete': False},
[36m(TaskRunner pid=6616)[0m                                                                 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                           'step_end': None,
[36m(TaskRunner pid=6616)[0m                                                                           'step_start': 0},
[36m(TaskRunner pid=6616)[0m                                                                 'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                                  'stack_depth': 32,
[36m(TaskRunner pid=6616)[0m                                                                                  'trace_alloc_max_entries': 100000}}},
[36m(TaskRunner pid=6616)[0m                                    'prompt_length': 512,
[36m(TaskRunner pid=6616)[0m                                    'response_length': 1024,
[36m(TaskRunner pid=6616)[0m                                    'skip_dump_dir': '/tmp/rollout_dump',
[36m(TaskRunner pid=6616)[0m                                    'skip_rollout': False,
[36m(TaskRunner pid=6616)[0m                                    'skip_tokenizer_init': True,
[36m(TaskRunner pid=6616)[0m                                    'temperature': 1.0,
[36m(TaskRunner pid=6616)[0m                                    'tensor_model_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m                                    'top_k': -1,
[36m(TaskRunner pid=6616)[0m                                    'top_p': 0.95,
[36m(TaskRunner pid=6616)[0m                                    'trace': {'_target_': 'verl.workers.config.TraceConfig',
[36m(TaskRunner pid=6616)[0m                                              'backend': None,
[36m(TaskRunner pid=6616)[0m                                              'token2text': False},
[36m(TaskRunner pid=6616)[0m                                    'update_weights_bucket_megabytes': 512,
[36m(TaskRunner pid=6616)[0m                                    'val_kwargs': {'_target_': 'verl.workers.config.SamplingConfig',
[36m(TaskRunner pid=6616)[0m                                                   'do_sample': False,
[36m(TaskRunner pid=6616)[0m                                                   'n': 1,
[36m(TaskRunner pid=6616)[0m                                                   'temperature': 0,
[36m(TaskRunner pid=6616)[0m                                                   'top_k': -1,
[36m(TaskRunner pid=6616)[0m                                                   'top_p': 1.0}}},
[36m(TaskRunner pid=6616)[0m  'algorithm': {'_target_': 'verl.trainer.config.AlgoConfig',
[36m(TaskRunner pid=6616)[0m                'adv_estimator': 'gae',
[36m(TaskRunner pid=6616)[0m                'gamma': 1.0,
[36m(TaskRunner pid=6616)[0m                'kl_ctrl': {'_target_': 'verl.trainer.config.KLControlConfig',
[36m(TaskRunner pid=6616)[0m                            'horizon': 10000,
[36m(TaskRunner pid=6616)[0m                            'kl_coef': 0.01,
[36m(TaskRunner pid=6616)[0m                            'target_kl': 0.1,
[36m(TaskRunner pid=6616)[0m                            'type': 'fixed'},
[36m(TaskRunner pid=6616)[0m                'kl_penalty': 'kl',
[36m(TaskRunner pid=6616)[0m                'lam': 1.0,
[36m(TaskRunner pid=6616)[0m                'norm_adv_by_std_in_grpo': True,
[36m(TaskRunner pid=6616)[0m                'pf_ppo': {'reweight_method': 'pow', 'weight_pow': 2.0},
[36m(TaskRunner pid=6616)[0m                'rollout_is': False,
[36m(TaskRunner pid=6616)[0m                'rollout_is_level': 'token',
[36m(TaskRunner pid=6616)[0m                'rollout_is_mode': 'truncate',
[36m(TaskRunner pid=6616)[0m                'rollout_is_threshold': None,
[36m(TaskRunner pid=6616)[0m                'rollout_is_threshold_lower': None,
[36m(TaskRunner pid=6616)[0m                'rollout_is_veto_threshold': 0.0001,
[36m(TaskRunner pid=6616)[0m                'use_kl_in_reward': False,
[36m(TaskRunner pid=6616)[0m                'use_pf_ppo': False},
[36m(TaskRunner pid=6616)[0m  'critic': {'_target_': 'verl.workers.config.FSDPCriticConfig',
[36m(TaskRunner pid=6616)[0m             'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',
[36m(TaskRunner pid=6616)[0m                            'async_save': False,
[36m(TaskRunner pid=6616)[0m                            'load_contents': ['model', 'optimizer', 'extra'],
[36m(TaskRunner pid=6616)[0m                            'save_contents': ['model', 'optimizer', 'extra']},
[36m(TaskRunner pid=6616)[0m             'cliprange_value': 0.5,
[36m(TaskRunner pid=6616)[0m             'enable': None,
[36m(TaskRunner pid=6616)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=6616)[0m             'forward_micro_batch_size': None,
[36m(TaskRunner pid=6616)[0m             'forward_micro_batch_size_per_gpu': 8,
[36m(TaskRunner pid=6616)[0m             'grad_clip': 1.0,
[36m(TaskRunner pid=6616)[0m             'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=6616)[0m             'model': {'_target_': 'verl.workers.config.FSDPCriticModelCfg',
[36m(TaskRunner pid=6616)[0m                       'enable_activation_offload': False,
[36m(TaskRunner pid=6616)[0m                       'enable_gradient_checkpointing': False,
[36m(TaskRunner pid=6616)[0m                       'external_lib': None,
[36m(TaskRunner pid=6616)[0m                       'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=6616)[0m                                       'entropy_checkpointing': False,
[36m(TaskRunner pid=6616)[0m                                       'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=6616)[0m                                       'forward_only': False,
[36m(TaskRunner pid=6616)[0m                                       'forward_prefetch': False,
[36m(TaskRunner pid=6616)[0m                                       'fsdp_size': -1,
[36m(TaskRunner pid=6616)[0m                                       'model_dtype': 'fp32',
[36m(TaskRunner pid=6616)[0m                                       'offload_policy': False,
[36m(TaskRunner pid=6616)[0m                                       'optimizer_offload': False,
[36m(TaskRunner pid=6616)[0m                                       'param_offload': False,
[36m(TaskRunner pid=6616)[0m                                       'reshard_after_forward': True,
[36m(TaskRunner pid=6616)[0m                                       'strategy': 'fsdp',
[36m(TaskRunner pid=6616)[0m                                       'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m                                       'use_orig_params': False,
[36m(TaskRunner pid=6616)[0m                                       'use_torch_compile': True,
[36m(TaskRunner pid=6616)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=6616)[0m                       'lora_alpha': 32,
[36m(TaskRunner pid=6616)[0m                       'lora_rank': 16,
[36m(TaskRunner pid=6616)[0m                       'override_config': {},
[36m(TaskRunner pid=6616)[0m                       'path': 'Qwen/Qwen2.5-1.5B-Instruct',
[36m(TaskRunner pid=6616)[0m                       'target_modules': 'all-linear',
[36m(TaskRunner pid=6616)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-1.5B-Instruct',
[36m(TaskRunner pid=6616)[0m                       'trust_remote_code': False,
[36m(TaskRunner pid=6616)[0m                       'use_remove_padding': False,
[36m(TaskRunner pid=6616)[0m                       'use_shm': False},
[36m(TaskRunner pid=6616)[0m             'optim': {'_target_': 'verl.workers.config.FSDPOptimizerConfig',
[36m(TaskRunner pid=6616)[0m                       'betas': [0.9, 0.999],
[36m(TaskRunner pid=6616)[0m                       'clip_grad': 1.0,
[36m(TaskRunner pid=6616)[0m                       'lr': 0.0001,
[36m(TaskRunner pid=6616)[0m                       'lr_scheduler_type': 'constant',
[36m(TaskRunner pid=6616)[0m                       'lr_warmup_steps': -1,
[36m(TaskRunner pid=6616)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=6616)[0m                       'min_lr_ratio': 0.0,
[36m(TaskRunner pid=6616)[0m                       'num_cycles': 0.5,
[36m(TaskRunner pid=6616)[0m                       'total_training_steps': -1,
[36m(TaskRunner pid=6616)[0m                       'warmup_style': None,
[36m(TaskRunner pid=6616)[0m                       'weight_decay': 0.01},
[36m(TaskRunner pid=6616)[0m             'ppo_epochs': 1,
[36m(TaskRunner pid=6616)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=6616)[0m             'ppo_micro_batch_size': None,
[36m(TaskRunner pid=6616)[0m             'ppo_micro_batch_size_per_gpu': 8,
[36m(TaskRunner pid=6616)[0m             'ppo_mini_batch_size': 256,
[36m(TaskRunner pid=6616)[0m             'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=6616)[0m                          'all_ranks': False,
[36m(TaskRunner pid=6616)[0m                          'enable': False,
[36m(TaskRunner pid=6616)[0m                          'ranks': [],
[36m(TaskRunner pid=6616)[0m                          'save_path': 'outputs/profile',
[36m(TaskRunner pid=6616)[0m                          'tool': None,
[36m(TaskRunner pid=6616)[0m                          'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=6616)[0m                                                  'analysis': True,
[36m(TaskRunner pid=6616)[0m                                                  'contents': [],
[36m(TaskRunner pid=6616)[0m                                                  'discrete': False,
[36m(TaskRunner pid=6616)[0m                                                  'level': 'level1'},
[36m(TaskRunner pid=6616)[0m                                          'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=6616)[0m                                                   'discrete': False},
[36m(TaskRunner pid=6616)[0m                                          'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=6616)[0m                                                    'step_end': None,
[36m(TaskRunner pid=6616)[0m                                                    'step_start': 0},
[36m(TaskRunner pid=6616)[0m                                          'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(TaskRunner pid=6616)[0m                                                           'stack_depth': 32,
[36m(TaskRunner pid=6616)[0m                                                           'trace_alloc_max_entries': 100000}}},
[36m(TaskRunner pid=6616)[0m             'rollout_n': 1,
[36m(TaskRunner pid=6616)[0m             'shuffle': False,
[36m(TaskRunner pid=6616)[0m             'strategy': 'fsdp',
[36m(TaskRunner pid=6616)[0m             'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m             'use_dynamic_bsz': False},
[36m(TaskRunner pid=6616)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(TaskRunner pid=6616)[0m  'data': {'apply_chat_template_kwargs': {},
[36m(TaskRunner pid=6616)[0m           'custom_cls': {'name': None, 'path': None},
[36m(TaskRunner pid=6616)[0m           'datagen': {'name': None, 'path': None},
[36m(TaskRunner pid=6616)[0m           'dataloader_num_workers': 8,
[36m(TaskRunner pid=6616)[0m           'filter_overlong_prompts': False,
[36m(TaskRunner pid=6616)[0m           'filter_overlong_prompts_workers': 1,
[36m(TaskRunner pid=6616)[0m           'image_key': 'images',
[36m(TaskRunner pid=6616)[0m           'max_prompt_length': 512,
[36m(TaskRunner pid=6616)[0m           'max_response_length': 1024,
[36m(TaskRunner pid=6616)[0m           'prompt_key': 'prompt',
[36m(TaskRunner pid=6616)[0m           'return_full_prompt': False,
[36m(TaskRunner pid=6616)[0m           'return_multi_modal_inputs': True,
[36m(TaskRunner pid=6616)[0m           'return_raw_chat': False,
[36m(TaskRunner pid=6616)[0m           'return_raw_input_ids': False,
[36m(TaskRunner pid=6616)[0m           'reward_fn_key': 'data_source',
[36m(TaskRunner pid=6616)[0m           'sampler': {'class_name': None, 'class_path': None},
[36m(TaskRunner pid=6616)[0m           'seed': None,
[36m(TaskRunner pid=6616)[0m           'shuffle': True,
[36m(TaskRunner pid=6616)[0m           'tokenizer': None,
[36m(TaskRunner pid=6616)[0m           'train_batch_size': 2048,
[36m(TaskRunner pid=6616)[0m           'train_files': '/workspace/data/gsm8k/train.parquet',
[36m(TaskRunner pid=6616)[0m           'train_max_samples': -1,
[36m(TaskRunner pid=6616)[0m           'truncation': 'error',
[36m(TaskRunner pid=6616)[0m           'trust_remote_code': False,
[36m(TaskRunner pid=6616)[0m           'use_shm': False,
[36m(TaskRunner pid=6616)[0m           'val_batch_size': None,
[36m(TaskRunner pid=6616)[0m           'val_files': '/workspace/data/gsm8k/test.parquet',
[36m(TaskRunner pid=6616)[0m           'val_max_samples': -1,
[36m(TaskRunner pid=6616)[0m           'validation_shuffle': False,
[36m(TaskRunner pid=6616)[0m           'video_key': 'videos'},
[36m(TaskRunner pid=6616)[0m  'global_profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=6616)[0m                      'global_tool_config': {'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=6616)[0m                                                      'controller_nsight_options': {'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=6616)[0m                                                                                    'cuda-memory-usage': 'true',
[36m(TaskRunner pid=6616)[0m                                                                                    'trace': 'cuda,nvtx,cublas,ucx'},
[36m(TaskRunner pid=6616)[0m                                                      'discrete': False,
[36m(TaskRunner pid=6616)[0m                                                      'worker_nsight_options': {'capture-range': 'cudaProfilerApi',
[36m(TaskRunner pid=6616)[0m                                                                                'capture-range-end': None,
[36m(TaskRunner pid=6616)[0m                                                                                'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=6616)[0m                                                                                'cuda-memory-usage': 'true',
[36m(TaskRunner pid=6616)[0m                                                                                'kill': 'none',
[36m(TaskRunner pid=6616)[0m                                                                                'trace': 'cuda,nvtx,cublas,ucx'}},
[36m(TaskRunner pid=6616)[0m                                             'torch_memory': {'context': 'all',
[36m(TaskRunner pid=6616)[0m                                                              'kw_args': {},
[36m(TaskRunner pid=6616)[0m                                                              'stack_depth': 32,
[36m(TaskRunner pid=6616)[0m                                                              'stacks': 'all',
[36m(TaskRunner pid=6616)[0m                                                              'trace_alloc_max_entries': 100000}},
[36m(TaskRunner pid=6616)[0m                      'profile_continuous_steps': False,
[36m(TaskRunner pid=6616)[0m                      'save_path': 'outputs/profile',
[36m(TaskRunner pid=6616)[0m                      'steps': None,
[36m(TaskRunner pid=6616)[0m                      'tool': None},
[36m(TaskRunner pid=6616)[0m  'ray_kwargs': {'ray_init': {'num_cpus': None}, 'timeline_json_file': None},
[36m(TaskRunner pid=6616)[0m  'reward_model': {'enable': False,
[36m(TaskRunner pid=6616)[0m                   'enable_resource_pool': False,
[36m(TaskRunner pid=6616)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=6616)[0m                   'launch_reward_fn_async': False,
[36m(TaskRunner pid=6616)[0m                   'max_length': None,
[36m(TaskRunner pid=6616)[0m                   'micro_batch_size': None,
[36m(TaskRunner pid=6616)[0m                   'micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=6616)[0m                   'model': {'external_lib': None,
[36m(TaskRunner pid=6616)[0m                             'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=6616)[0m                                             'forward_prefetch': False,
[36m(TaskRunner pid=6616)[0m                                             'fsdp_size': -1,
[36m(TaskRunner pid=6616)[0m                                             'param_offload': False,
[36m(TaskRunner pid=6616)[0m                                             'reshard_after_forward': True,
[36m(TaskRunner pid=6616)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=6616)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-1.5B-Instruct',
[36m(TaskRunner pid=6616)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(TaskRunner pid=6616)[0m                             'trust_remote_code': False,
[36m(TaskRunner pid=6616)[0m                             'use_fused_kernels': False,
[36m(TaskRunner pid=6616)[0m                             'use_remove_padding': False,
[36m(TaskRunner pid=6616)[0m                             'use_shm': False},
[36m(TaskRunner pid=6616)[0m                   'n_gpus_per_node': 0,
[36m(TaskRunner pid=6616)[0m                   'nnodes': 0,
[36m(TaskRunner pid=6616)[0m                   'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=6616)[0m                                'all_ranks': False,
[36m(TaskRunner pid=6616)[0m                                'enable': False,
[36m(TaskRunner pid=6616)[0m                                'ranks': [],
[36m(TaskRunner pid=6616)[0m                                'save_path': 'outputs/profile',
[36m(TaskRunner pid=6616)[0m                                'tool': None,
[36m(TaskRunner pid=6616)[0m                                'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=6616)[0m                                                        'analysis': True,
[36m(TaskRunner pid=6616)[0m                                                        'contents': [],
[36m(TaskRunner pid=6616)[0m                                                        'discrete': False,
[36m(TaskRunner pid=6616)[0m                                                        'level': 'level1'},
[36m(TaskRunner pid=6616)[0m                                                'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=6616)[0m                                                         'discrete': False},
[36m(TaskRunner pid=6616)[0m                                                'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=6616)[0m                                                          'step_end': None,
[36m(TaskRunner pid=6616)[0m                                                          'step_start': 0},
[36m(TaskRunner pid=6616)[0m                                                'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(TaskRunner pid=6616)[0m                                                                 'stack_depth': 32,
[36m(TaskRunner pid=6616)[0m                                                                 'trace_alloc_max_entries': 100000}}},
[36m(TaskRunner pid=6616)[0m                   'reward_manager': 'naive',
[36m(TaskRunner pid=6616)[0m                   'sandbox_fusion': {'max_concurrent': 64,
[36m(TaskRunner pid=6616)[0m                                      'memory_limit_mb': 1024,
[36m(TaskRunner pid=6616)[0m                                      'url': None},
[36m(TaskRunner pid=6616)[0m                   'strategy': 'fsdp',
[36m(TaskRunner pid=6616)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=6616)[0m                   'use_dynamic_bsz': False},
[36m(TaskRunner pid=6616)[0m  'trainer': {'balance_batch': True,
[36m(TaskRunner pid=6616)[0m              'critic_warmup': 0,
[36m(TaskRunner pid=6616)[0m              'default_hdfs_dir': None,
[36m(TaskRunner pid=6616)[0m              'default_local_dir': 'checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201',
[36m(TaskRunner pid=6616)[0m              'del_local_ckpt_after_load': False,
[36m(TaskRunner pid=6616)[0m              'device': 'cuda',
[36m(TaskRunner pid=6616)[0m              'esi_redundant_time': 0,
[36m(TaskRunner pid=6616)[0m              'experiment_name': 'qwen1.5b_kl0.01_20251022_035201',
[36m(TaskRunner pid=6616)[0m              'log_val_generations': 0,
[36m(TaskRunner pid=6616)[0m              'logger': ['console', 'wandb'],
[36m(TaskRunner pid=6616)[0m              'max_actor_ckpt_to_keep': None,
[36m(TaskRunner pid=6616)[0m              'max_critic_ckpt_to_keep': None,
[36m(TaskRunner pid=6616)[0m              'n_gpus_per_node': 2,
[36m(TaskRunner pid=6616)[0m              'nnodes': 1,
[36m(TaskRunner pid=6616)[0m              'project_name': 'verl_gsm8k_ppo_qwen1.5B',
[36m(TaskRunner pid=6616)[0m              'ray_wait_register_center_timeout': 300,
[36m(TaskRunner pid=6616)[0m              'resume_from_path': None,
[36m(TaskRunner pid=6616)[0m              'resume_mode': 'auto',
[36m(TaskRunner pid=6616)[0m              'rollout_data_dir': None,
[36m(TaskRunner pid=6616)[0m              'save_freq': 10,
[36m(TaskRunner pid=6616)[0m              'test_freq': 5,
[36m(TaskRunner pid=6616)[0m              'total_epochs': 10,
[36m(TaskRunner pid=6616)[0m              'total_training_steps': None,
[36m(TaskRunner pid=6616)[0m              'use_legacy_worker_impl': 'auto',
[36m(TaskRunner pid=6616)[0m              'val_before_train': True,
[36m(TaskRunner pid=6616)[0m              'val_only': False,
[36m(TaskRunner pid=6616)[0m              'validation_data_dir': None}}
[36m(TaskRunner pid=6616)[0m [validate_config] All configuration checks passed successfully!
[36m(TaskRunner pid=6616)[0m /workspace/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(TaskRunner pid=6616)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(TaskRunner pid=6616)[0m /workspace/verl/verl/workers/config/critic.py:200: UserWarning: using model in Critic Config is deprecated, please use model_config instead
[36m(TaskRunner pid=6616)[0m   super().__post_init__()
[36m(TaskRunner pid=6616)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=6616)[0m dataset len: 7473
[36m(TaskRunner pid=6616)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=6616)[0m dataset len: 1319
[36m(TaskRunner pid=6616)[0m Size of train dataloader: 3, Size of val dataloader: 1
[36m(TaskRunner pid=6616)[0m Total training steps: 30
[36m(TaskRunner pid=6616)[0m colocated worker base class <class 'verl.single_controller.base.worker.Worker'>
[36m(pid=7192)[0m /workspace/miniconda/envs/verl/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
[36m(pid=7192)[0m   import pynvml  # type: ignore[import]
[36m(pid=7192)[0m WARNING:2025-10-22 03:52:26,532:Skipping import of cpp extensions due to incompatible torch version 2.6.0+cu124 for torchao version 0.14.0         Please see GitHub issue #2919 for more info
[36m(WorkerDict pid=7191)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151645, 'pad_token_id': 151643}
[36m(WorkerDict pid=7192)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=7192)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=7191)[0m /workspace/miniconda/envs/verl/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=7191)[0m   import pynvml  # type: ignore[import][32m [repeated 3x across cluster][0m
[36m(pid=7191)[0m WARNING:2025-10-22 03:52:26,808:Skipping import of cpp extensions due to incompatible torch version 2.6.0+cu124 for torchao version 0.14.0         Please see GitHub issue #2919 for more info
[36m(WorkerDict pid=7192)[0m Skipping monkey patch for Qwen2ForTokenClassification as use_fused_kernels is False or fused_kernels_backend is None
[36m(WorkerDict pid=7192)[0m Applying LoRA to critic module
[36m(WorkerDict pid=7192)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=7192)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=7191)[0m PeftModelForCausalLM contains 1.56B parameters
[36m(WorkerDict pid=7191)[0m Before critic FSDP, memory allocated (GB): 0.00, memory reserved (GB): 0.00, device memory used/total (GB): 0.51/79.20
[36m(WorkerDict pid=7191)[0m NCCL version 2.21.5+cuda12.4
[36m(WorkerDict pid=7191)[0m After critic FSDP, memory allocated (GB): 2.91, memory reserved (GB): 5.22, device memory used/total (GB): 6.58/79.20
[36m(WorkerDict pid=7191)[0m Total steps: 30, num_warmup_steps: 0
[36m(WorkerDict pid=7191)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=7191)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=7191)[0m   "architectures": [
[36m(WorkerDict pid=7191)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=7191)[0m   ],
[36m(WorkerDict pid=7191)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=7191)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=7191)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=7191)[0m   "hidden_size": 1536,
[36m(WorkerDict pid=7191)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=7191)[0m   "intermediate_size": 8960,
[36m(WorkerDict pid=7191)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=7191)[0m   "max_window_layers": 21,
[36m(WorkerDict pid=7191)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=7191)[0m   "num_attention_heads": 12,
[36m(WorkerDict pid=7191)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=7191)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=7191)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=7191)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=7191)[0m   "rope_scaling": null,
[36m(WorkerDict pid=7191)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=7191)[0m   "sliding_window": 32768,
[36m(WorkerDict pid=7191)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=7191)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=7191)[0m   "transformers_version": "4.51.1",
[36m(WorkerDict pid=7191)[0m   "use_cache": true,
[36m(WorkerDict pid=7191)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=7191)[0m   "vocab_size": 151936
[36m(WorkerDict pid=7191)[0m }
[36m(WorkerDict pid=7191)[0m 
[36m(WorkerDict pid=7191)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=7191)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=7192)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=7192)[0m Applying LoRA to actor module
[36m(WorkerDict pid=7191)[0m Skipping monkey patch for Qwen2ForTokenClassification as use_fused_kernels is False or fused_kernels_backend is None
[36m(WorkerDict pid=7191)[0m Applying LoRA to critic module
[36m(WorkerDict pid=7192)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=7191)[0m PeftModelForCausalLM contains 1.56B parameters
[36m(WorkerDict pid=7191)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ff3c037a0e0>, policies=[functools.partial(<function lambda_auto_wrap_policy at 0x7ff3c0379bd0>, lambda_fn=<function get_fsdp_wrap_policy.<locals>.lambda_policy_fn at 0x7fcc3f9fc820>), functools.partial(<function transformer_auto_wrap_policy at 0x7ff3c0379fc0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=7192)[0m /workspace/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=7192)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(WorkerDict pid=7191)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=7191)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=7191)[0m Total steps: 30, num_warmup_steps: 0
[36m(WorkerDict pid=7191)[0m Actor use_remove_padding=False
[36m(WorkerDict pid=7191)[0m Actor use_fused_kernels=False
[36m(WorkerDict pid=7191)[0m WARNING 10-22 03:52:54 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fcb8c0edff0>
[36m(WorkerDict pid=7191)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=7191)[0m Applying LoRA to actor module
[36m(WorkerDict pid=7191)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'repetition_penalty': 1.0, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(WorkerDict pid=7192)[0m WARNING 10-22 03:52:55 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3c5737df60>
[36m(WorkerDict pid=7191)[0m /workspace/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=7191)[0m   warnings.warn(
[36m(WorkerDict pid=7192)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=7191)[0m /workspace/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=7191)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(TaskRunner pid=6616)[0m /workspace/miniconda/envs/verl/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[36m(TaskRunner pid=6616)[0m /workspace/miniconda/envs/verl/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
[36m(TaskRunner pid=6616)[0m wandb: Currently logged in as: vbadoni (vbadoni-princeton-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(TaskRunner pid=6616)[0m wandb: Tracking run with wandb version 0.22.2
[36m(TaskRunner pid=6616)[0m wandb: Run data is saved locally in /workspace/rl_cot_monitorability/scripts/wandb/run-20251022_035452-ob5kpvhg
[36m(TaskRunner pid=6616)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(TaskRunner pid=6616)[0m wandb: Syncing run qwen1.5b_kl0.01_20251022_035201
[36m(TaskRunner pid=6616)[0m wandb: ⭐️ View project at https://wandb.ai/vbadoni-princeton-university/verl_gsm8k_ppo_qwen1.5B
[36m(TaskRunner pid=6616)[0m wandb: 🚀 View run at https://wandb.ai/vbadoni-princeton-university/verl_gsm8k_ppo_qwen1.5B/runs/ob5kpvhg
[36m(TaskRunner pid=6616)[0m Checkpoint tracker file does not exist: /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/latest_checkpointed_iteration.txt
[36m(TaskRunner pid=6616)[0m Training from scratch
[36m(TaskRunner pid=6616)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 0}
[36m(WorkerDict pid=7192)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 1024, 'repetition_penalty': 1.0, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 0.95, 'ignore_eos': False}
[36m(TaskRunner pid=6616)[0m validation generation end
[36m(TaskRunner pid=6616)[0m [prompt] system
[36m(TaskRunner pid=6616)[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
[36m(TaskRunner pid=6616)[0m user
[36m(TaskRunner pid=6616)[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after "####".
[36m(TaskRunner pid=6616)[0m assistant
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m [response] To determine how much Janet makes every day at the farmers' market, we need to follow these steps:
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 1. Calculate the total number of eggs laid per day.
[36m(TaskRunner pid=6616)[0m 2. Determine how many eggs are eaten for breakfast.
[36m(TaskRunner pid=6616)[0m 3. Determine how many eggs are used to bake muffins.
[36m(TaskRunner pid=6616)[0m 4. Calculate the number of eggs left for sale at the farmers' market.
[36m(TaskRunner pid=6616)[0m 5. Calculate the total revenue from selling the eggs at the farmers' market.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m Let's go through each step:
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 1. **Total number of eggs laid per day**: Janet's ducks lay 16 eggs per day.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 2. **Eggs eaten for breakfast**: Janet eats 3 eggs for breakfast every morning.
[36m(TaskRunner pid=6616)[0m    \[
[36m(TaskRunner pid=6616)[0m    \text{Eggs eaten for breakfast} = 3
[36m(TaskRunner pid=6616)[0m    \]
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 3. **Eggs used to bake muffins**: Janet bakes muffins for her friends every day with 4 eggs.
[36m(TaskRunner pid=6616)[0m    \[
[36m(TaskRunner pid=6616)[0m    \text{Eggs used to bake muffins} = 4
[36m(TaskRunner pid=6616)[0m    \]
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 4. **Eggs left for sale at the farmers' market**: Subtract the eggs eaten for breakfast and the eggs used to bake muffins from the total number of eggs laid.
[36m(TaskRunner pid=6616)[0m    \[
[36m(TaskRunner pid=6616)[0m    \text{Eggs left for sale} = 16 - 3 - 4 = 9
[36m(TaskRunner pid=6616)[0m    \]
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 5. **Total revenue from selling the eggs at the farmers' market**: Janet sells each egg for $2.
[36m(TaskRunner pid=6616)[0m    \[
[36m(TaskRunner pid=6616)[0m    \text{Total revenue} = 9 \text{ eggs} \times \$2/\text{egg} = \$18
[36m(TaskRunner pid=6616)[0m    \]
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m Therefore, Janet makes $18 every day at the farmers' market.
[36m(TaskRunner pid=6616)[0m [ground_truth] 18
[36m(TaskRunner pid=6616)[0m [score] 0.0
[36m(TaskRunner pid=6616)[0m ("Initial validation metrics: {'val-core/openai/gsm8k/reward/mean@1': "
[36m(TaskRunner pid=6616)[0m  'np.float64(0.07808946171341925)}')
[36m(TaskRunner pid=6616)[0m step:0 - val-core/openai/gsm8k/reward/mean@1:np.float64(0.07808946171341925)
[36m(TaskRunner pid=6616)[0m 
Training Progress:   0%|          | 0/30 [00:00<?, ?it/s]
[36m(WorkerDict pid=7192)[0m /workspace/miniconda/envs/verl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(TaskRunner pid=6616)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=7192)[0m WARNING 10-22 03:55:59 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:1 - global_seqlen/min:376910 - global_seqlen/max:383540 - global_seqlen/minmax_diff:6630 - global_seqlen/balanced_min:380225 - global_seqlen/balanced_max:380225 - global_seqlen/mean:380225.0 - actor/entropy:0.2924998104572296 - critic/vf_loss:np.float64(0.19489884545328096) - critic/vf_clipfrac:np.float64(0.44420288595574675) - critic/vpred_mean:np.float64(-0.8230293459237146) - critic/grad_norm:np.float64(8.879704013466835) - perf/mfu/critic:np.float64(0.03949103369181317) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00044343810216673774) - actor/pg_clipfrac:np.float64(0.01130852920232428) - actor/ppo_kl:np.float64(-1.7891188782925838e-05) - actor/pg_clipfrac_lower:np.float64(8.480572864755231e-05) - actor/grad_norm:np.float64(0.04770243028178811) - perf/mfu/actor:np.float64(0.041120360444383344) - perf/max_memory_allocated_gb:np.float64(73.98283958435059) - perf/max_memory_reserved_gb:np.float64(78.279296875) - perf/cpu_memory_used_gb:np.float64(85.33320999145508) - actor/lr:np.float64(0.0001) - training/global_step:1 - training/epoch:0 - critic/score/mean:0.14453125 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.14453125 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:2.5633035694028194e-09 - critic/advantages/max:4.8647050857543945 - critic/advantages/min:-4.812094211578369 - critic/returns/mean:0.11894693225622177 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:-1.3828125 - critic/values/max:9.625 - critic/values/min:-11.625 - critic/vf_explained_var:-48.31560516357422 - response_length/mean:267.41015625 - response_length/max:853.0 - response_length/min:5.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:267.41015625 - response_length_non_aborted/max:853.0 - response_length_non_aborted/min:5.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:103.9033203125 - prompt_length/max:232.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.00044761598110198975 - timing_s/generate_sequences:20.713077545166016 - timing_s/generation_timing/max:20.87867546081543 - timing_s/generation_timing/min:20.547481536865234 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:39.5530960932374 - timing_s/reward:0.4623941741883755 - timing_s/old_log_prob:28.8825905546546 - timing_s/values:39.51579726114869 - timing_s/adv:0.35053062066435814 - timing_s/update_critic:106.29928584396839 - timing_s/update_actor:102.20873342081904 - timing_s/step:317.3826474621892 - timing_s/stop_profile:9.327009320259094e-05 - timing_per_token_ms/values:0.051963702098952846 - timing_per_token_ms/gen:0.07222251941590598 - timing_per_token_ms/update_critic:0.13978471410870982 - timing_per_token_ms/adv:0.0004609515690240754 - timing_per_token_ms/update_actor:0.13440559329452173 - perf/total_num_tokens:760450 - perf/time_per_step:317.3826474621892 - perf/throughput:1198.00185372547
[36m(WorkerDict pid=7191)[0m WARNING 10-22 03:56:00 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:   3%|▎         | 1/30 [05:19<2:34:36, 319.89s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:01:20 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:2 - global_seqlen/min:392419 - global_seqlen/max:393496 - global_seqlen/minmax_diff:1077 - global_seqlen/balanced_min:392957 - global_seqlen/balanced_max:392958 - global_seqlen/mean:392957.5 - actor/entropy:0.25716355443000793 - critic/vf_loss:np.float64(0.08124955336097628) - critic/vf_clipfrac:np.float64(0.34046924744416174) - critic/vpred_mean:np.float64(-0.2711455969808867) - critic/grad_norm:np.float64(6.515991672873497) - perf/mfu/critic:np.float64(0.04046175912332625) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00040532823322791955) - actor/pg_clipfrac:np.float64(0.005417034736979076) - actor/ppo_kl:np.float64(-0.0009465621861693974) - actor/pg_clipfrac_lower:np.float64(3.1803442652744707e-06) - actor/grad_norm:np.float64(0.040397160686552525) - perf/mfu/actor:np.float64(0.042348685030583214) - perf/max_memory_allocated_gb:np.float64(74.02531242370605) - perf/max_memory_reserved_gb:np.float64(80.478515625) - perf/cpu_memory_used_gb:np.float64(123.03672790527344) - actor/lr:np.float64(0.0001) - training/global_step:2 - training/epoch:0 - critic/score/mean:0.1845703125 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.1845703125 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-4.68042209433861e-08 - critic/advantages/max:5.339689254760742 - critic/advantages/min:-5.775634765625 - critic/returns/mean:0.1534920334815979 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:-0.72265625 - critic/values/max:8.25 - critic/values/min:-8.625 - critic/vf_explained_var:-18.212209701538086 - response_length/mean:279.68994140625 - response_length/max:1024.0 - response_length/min:4.0 - response_length/clip_ratio:0.00244140625 - response_length_non_aborted/mean:279.68994140625 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.00244140625 - response/aborted_ratio:0.0 - prompt_length/mean:104.0576171875 - prompt_length/max:201.0 - prompt_length/min:56.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:9.798258543014526e-05 - timing_s/generate_sequences:23.635087966918945 - timing_s/generation_timing/max:23.745820999145508 - timing_s/generation_timing/min:23.524354934692383 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:45.28001845255494 - timing_s/reward:0.4722775034606457 - timing_s/old_log_prob:27.765034947544336 - timing_s/values:39.61261000111699 - timing_s/adv:0.2534470744431019 - timing_s/update_critic:107.4174915254116 - timing_s/update_actor:102.46902943775058 - timing_s/step:323.37742123007774 - timing_s/stop_profile:8.628144860267639e-05 - timing_per_token_ms/values:0.05040317337258735 - timing_per_token_ms/gen:0.07904962151614414 - timing_per_token_ms/update_critic:0.13667825595059466 - timing_per_token_ms/adv:0.00032248662316293984 - timing_per_token_ms/update_actor:0.1303818217463092 - perf/total_num_tokens:785915 - perf/time_per_step:323.37742123007774 - perf/throughput:1215.166780986905
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:01:20 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:   7%|▋         | 2/30 [10:43<2:30:16, 322.00s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:06:41 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:3 - global_seqlen/min:383097 - global_seqlen/max:385338 - global_seqlen/minmax_diff:2241 - global_seqlen/balanced_min:384217 - global_seqlen/balanced_max:384218 - global_seqlen/mean:384217.5 - actor/entropy:0.21813920140266418 - critic/vf_loss:np.float64(0.0371943559293868) - critic/vf_clipfrac:np.float64(0.25389232826455554) - critic/vpred_mean:np.float64(-0.08980861841064325) - critic/grad_norm:np.float64(5.97724986076355) - perf/mfu/critic:np.float64(0.040147090640827464) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00029611773280180387) - actor/pg_clipfrac:np.float64(0.006299273175727649) - actor/ppo_kl:np.float64(-0.00033791584774434114) - actor/pg_clipfrac_lower:np.float64(1.1778692623920506e-05) - actor/grad_norm:np.float64(0.044120076578110456) - perf/mfu/actor:np.float64(0.03946327664218047) - perf/max_memory_allocated_gb:np.float64(74.02531242370605) - perf/max_memory_reserved_gb:np.float64(80.478515625) - perf/cpu_memory_used_gb:np.float64(123.16924667358398) - actor/lr:np.float64(0.0001) - training/global_step:3 - training/epoch:0 - critic/score/mean:0.2119140625 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.2119140625 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-1.4730995978595729e-08 - critic/advantages/max:6.473549842834473 - critic/advantages/min:-6.697513580322266 - critic/returns/mean:0.1861926019191742 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:-0.494140625 - critic/values/max:6.375 - critic/values/min:-6.5 - critic/vf_explained_var:-6.323366165161133 - response_length/mean:271.72802734375 - response_length/max:1024.0 - response_length/min:4.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:271.72802734375 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:103.484375 - prompt_length/max:256.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.0001015588641166687 - timing_s/generate_sequences:21.574966430664062 - timing_s/generation_timing/max:22.64028549194336 - timing_s/generation_timing/min:20.509645462036133 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:41.63160151615739 - timing_s/reward:0.46123621612787247 - timing_s/old_log_prob:27.348482452332973 - timing_s/values:46.15367250144482 - timing_s/adv:0.23479920253157616 - timing_s/update_critic:105.56231904774904 - timing_s/update_actor:107.51568205282092 - timing_s/step:329.00982566922903 - timing_s/stop_profile:0.00018265098333358765 - timing_per_token_ms/values:0.060061908296010484 - timing_per_token_ms/gen:0.07480984065767843 - timing_per_token_ms/update_critic:0.13737312726222653 - timing_per_token_ms/adv:0.00030555506000061965 - timing_per_token_ms/update_actor:0.13991512886948268 - perf/total_num_tokens:768435 - perf/time_per_step:329.00982566922903 - perf/throughput:1167.799469874417
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:06:41 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  10%|█         | 3/30 [16:12<2:26:21, 325.25s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:12:13 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:4 - global_seqlen/min:379510 - global_seqlen/max:380882 - global_seqlen/minmax_diff:1372 - global_seqlen/balanced_min:380196 - global_seqlen/balanced_max:380196 - global_seqlen/mean:380196.0 - actor/entropy:0.18987050652503967 - critic/vf_loss:np.float64(0.022824919429695) - critic/vf_clipfrac:np.float64(0.19627416083585558) - critic/vpred_mean:np.float64(0.09711853185172004) - critic/grad_norm:np.float64(5.2176229655742645) - perf/mfu/critic:np.float64(0.04002006624985126) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00037587888171941586) - actor/pg_clipfrac:np.float64(0.005839474850063198) - actor/ppo_kl:np.float64(0.001111459473698062) - actor/pg_clipfrac_lower:np.float64(2.1151694340915128e-05) - actor/grad_norm:np.float64(0.04606005363166332) - perf/mfu/actor:np.float64(0.04013236270019571) - perf/max_memory_allocated_gb:np.float64(74.06899213790894) - perf/max_memory_reserved_gb:np.float64(80.609375) - perf/cpu_memory_used_gb:np.float64(127.93526077270508) - actor/lr:np.float64(0.0001) - training/global_step:4 - training/epoch:1 - critic/score/mean:0.34619140625 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.34619140625 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:4.4569084423073946e-08 - critic/advantages/max:7.125146865844727 - critic/advantages/min:-6.477917671203613 - critic/returns/mean:0.30784234404563904 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:-0.25390625 - critic/values/max:4.75 - critic/values/min:-6.40625 - critic/vf_explained_var:-2.1565191745758057 - response_length/mean:267.59619140625 - response_length/max:1024.0 - response_length/min:5.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:267.59619140625 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:5.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:103.68896484375 - prompt_length/max:256.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.0004389435052871704 - timing_s/generate_sequences:21.097000122070312 - timing_s/generation_timing/max:21.12122917175293 - timing_s/generation_timing/min:21.072771072387695 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:40.18957423791289 - timing_s/reward:0.4548981040716171 - timing_s/old_log_prob:27.706116188317537 - timing_s/values:40.443360801786184 - timing_s/adv:0.3563791289925575 - timing_s/update_critic:104.95189787074924 - timing_s/update_actor:104.5788446366787 - timing_s/step:318.80979783833027 - timing_s/stop_profile:8.491799235343933e-05 - timing_per_token_ms/values:0.053187514863105065 - timing_per_token_ms/gen:0.07333368775814934 - timing_per_token_ms/update_critic:0.13802341143877006 - timing_per_token_ms/adv:0.00046867816730391366 - timing_per_token_ms/update_actor:0.13753280496990855 - perf/total_num_tokens:760392 - perf/time_per_step:318.80979783833027 - perf/throughput:1192.5480414275064
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:12:13 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  13%|█▎        | 4/30 [21:34<2:20:20, 323.88s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:17:30 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 5}
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:17:31 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:22:50 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m validation generation end
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:22:52 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m [prompt] system
[36m(TaskRunner pid=6616)[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
[36m(TaskRunner pid=6616)[0m user
[36m(TaskRunner pid=6616)[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after "####".
[36m(TaskRunner pid=6616)[0m assistant
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m [response] Sure, let's break down the problem step by step:
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 1. **Total eggs laid per day**: Janet's ducks lay 16 eggs per day.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 2. **Eggs eaten for breakfast**: Janet eats 3 eggs for breakfast every morning.
[36m(TaskRunner pid=6616)[0m    - Eggs eaten for breakfast = 3 eggs
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 3. **Eggs used to bake muffins**: Janet bakes muffins for her friends every day with 4 eggs.
[36m(TaskRunner pid=6616)[0m    - Eggs used for muffins = 4 eggs
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 4. **Eggs left for sale at the farmers' market**: To find out how many eggs are left for sale, we subtract the eggs eaten for breakfast and the eggs used for muffins from the total eggs laid per day.
[36m(TaskRunner pid=6616)[0m    - Eggs left for sale = Total eggs laid per day - Eggs eaten for breakfast - Eggs used for muffins
[36m(TaskRunner pid=6616)[0m    - Eggs left for sale = 16 eggs - 3 eggs - 4 eggs
[36m(TaskRunner pid=6616)[0m    - Eggs left for sale = 16 - 3 - 4
[36m(TaskRunner pid=6616)[0m    - Eggs left for sale = 9 eggs
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 5. **Earnings from selling eggs at the farmers' market**: Janet sells each egg for $2.
[36m(TaskRunner pid=6616)[0m    - Earnings from selling eggs = Eggs left for sale × Price per egg
[36m(TaskRunner pid=6616)[0m    - Earnings from selling eggs = 9 eggs × $2 per egg
[36m(TaskRunner pid=6616)[0m    - Earnings from selling eggs = $18
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m Therefore, Janet makes $18 every day at the farmers' market.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m The final answer is: #### 18
[36m(TaskRunner pid=6616)[0m [ground_truth] 18
[36m(TaskRunner pid=6616)[0m [score] 1.0
[36m(TaskRunner pid=6616)[0m step:5 - global_seqlen/min:374582 - global_seqlen/max:386221 - global_seqlen/minmax_diff:11639 - global_seqlen/balanced_min:380401 - global_seqlen/balanced_max:380402 - global_seqlen/mean:380401.5 - actor/entropy:0.18737545609474182 - critic/vf_loss:np.float64(0.021008004539908143) - critic/vf_clipfrac:np.float64(0.2558320004027337) - critic/vpred_mean:np.float64(0.4214053409259577) - critic/grad_norm:np.float64(7.368841111660004) - perf/mfu/critic:np.float64(0.03946767947334285) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0008541222159408335) - actor/pg_clipfrac:np.float64(0.005540262761542181) - actor/ppo_kl:np.float64(0.00019051326946495362) - actor/pg_clipfrac_lower:np.float64(2.1451126031024614e-06) - actor/grad_norm:np.float64(0.04643436521291733) - perf/mfu/actor:np.float64(0.039707318532039876) - perf/max_memory_allocated_gb:np.float64(74.06899213790894) - perf/max_memory_reserved_gb:np.float64(80.615234375) - perf/cpu_memory_used_gb:np.float64(142.77832412719727) - actor/lr:np.float64(0.0001) - val-core/openai/gsm8k/reward/mean@1:np.float64(0.6921910538286581) - training/global_step:5 - training/epoch:1 - critic/score/mean:0.5888671875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.5888671875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-1.440720609480195e-08 - critic/advantages/max:6.827733993530273 - critic/advantages/min:-6.863396167755127 - critic/returns/mean:0.5385623574256897 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:-0.05224609375 - critic/values/max:4.25 - critic/values/min:-4.40625 - critic/vf_explained_var:-1.0015714168548584 - response_length/mean:267.8798828125 - response_length/max:1024.0 - response_length/min:5.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:267.8798828125 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:5.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:103.60595703125 - prompt_length/max:238.0 - prompt_length/min:63.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:6.210803985595703e-05 - timing_s/generate_sequences:21.10449981689453 - timing_s/generation_timing/max:22.51477813720703 - timing_s/generation_timing/min:19.6942195892334 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:39.29922077804804 - timing_s/reward:0.2754686698317528 - timing_s/old_log_prob:27.221311073750257 - timing_s/values:39.743951950222254 - timing_s/adv:0.25349147617816925 - timing_s/update_critic:106.42628036811948 - timing_s/update_actor:105.76502594724298 - timing_s/step:319.0581055767834 - timing_s/testing:36.86850155517459 - timing_s/stop_profile:5.995854735374451e-05 - timing_per_token_ms/values:0.05223947848552418 - timing_per_token_ms/gen:0.07163312318962928 - timing_per_token_ms/update_critic:0.1398867780070787 - timing_per_token_ms/adv:0.00033318937514464225 - timing_per_token_ms/update_actor:0.13901762472971713 - perf/total_num_tokens:760803 - perf/time_per_step:319.0581055767834 - perf/throughput:1192.2640213522295
[36m(TaskRunner pid=6616)[0m 
Training Progress:  17%|█▋        | 5/30 [27:30<2:19:46, 335.47s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:23:26 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:6 - global_seqlen/min:377210 - global_seqlen/max:378144 - global_seqlen/minmax_diff:934 - global_seqlen/balanced_min:377677 - global_seqlen/balanced_max:377677 - global_seqlen/mean:377677.0 - actor/entropy:0.1728171557188034 - critic/vf_loss:np.float64(0.009406604569448973) - critic/vf_clipfrac:np.float64(0.011454704204311383) - critic/vpred_mean:np.float64(0.6383510085288435) - critic/grad_norm:np.float64(1.5213482454419136) - perf/mfu/critic:np.float64(0.026351925080973018) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0006808519654555312) - actor/pg_clipfrac:np.float64(0.004153025104869812) - actor/ppo_kl:np.float64(0.0007746452775592161) - actor/pg_clipfrac_lower:np.float64(4.1043158489628695e-06) - actor/grad_norm:np.float64(0.044569896534085274) - perf/mfu/actor:np.float64(0.0382552248978698) - perf/max_memory_allocated_gb:np.float64(74.06899213790894) - perf/max_memory_reserved_gb:np.float64(80.615234375) - perf/cpu_memory_used_gb:np.float64(199.22698211669922) - actor/lr:np.float64(0.0001) - training/global_step:6 - training/epoch:1 - critic/score/mean:0.71728515625 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.71728515625 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-1.4094356792782037e-08 - critic/advantages/max:5.622389793395996 - critic/advantages/min:-6.328392505645752 - critic/returns/mean:0.6704925298690796 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.5859375 - critic/values/max:3.640625 - critic/values/min:-2.390625 - critic/vf_explained_var:-0.5667250156402588 - response_length/mean:265.63232421875 - response_length/max:1024.0 - response_length/min:4.0 - response_length/clip_ratio:0.00146484375 - response_length_non_aborted/mean:265.63232421875 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.00146484375 - response/aborted_ratio:0.0 - prompt_length/mean:103.19287109375 - prompt_length/max:222.0 - prompt_length/min:62.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:4.445761442184448e-05 - timing_s/generate_sequences:33.399314880371094 - timing_s/generation_timing/max:34.838504791259766 - timing_s/generation_timing/min:31.960128784179688 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:52.126844726502895 - timing_s/reward:0.4875609911978245 - timing_s/old_log_prob:38.6890482455492 - timing_s/values:56.50106642022729 - timing_s/adv:0.36006131768226624 - timing_s/update_critic:157.95677806064487 - timing_s/update_actor:108.86778093874454 - timing_s/step:415.08106043189764 - timing_s/stop_profile:9.897351264953613e-05 - timing_per_token_ms/values:0.07480077741062771 - timing_per_token_ms/gen:0.09581876368574928 - timing_per_token_ms/update_critic:0.20911622637947885 - timing_per_token_ms/adv:0.00047667890509915385 - timing_per_token_ms/update_actor:0.14412815837176285 - perf/total_num_tokens:755354 - perf/time_per_step:415.08106043189764 - perf/throughput:909.8873352762032
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:23:26 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  20%|██        | 6/30 [34:25<2:25:01, 362.57s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:30:24 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:7 - global_seqlen/min:379598 - global_seqlen/max:392153 - global_seqlen/minmax_diff:12555 - global_seqlen/balanced_min:385875 - global_seqlen/balanced_max:385876 - global_seqlen/mean:385875.5 - actor/entropy:0.171901136636734 - critic/vf_loss:np.float64(0.006382403518500723) - critic/vf_clipfrac:np.float64(0.0004287314056909963) - critic/vpred_mean:np.float64(0.7601074557751417) - critic/grad_norm:np.float64(1.5838505029678345) - perf/mfu/critic:np.float64(0.04071662589704447) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.001069479529490991) - actor/pg_clipfrac:np.float64(0.003980077816549965) - actor/ppo_kl:np.float64(0.0005274976929836583) - actor/pg_clipfrac_lower:np.float64(0.0) - actor/grad_norm:np.float64(0.04348361026495695) - perf/mfu/actor:np.float64(0.04107062941664599) - perf/max_memory_allocated_gb:np.float64(74.06899213790894) - perf/max_memory_reserved_gb:np.float64(80.615234375) - perf/cpu_memory_used_gb:np.float64(191.16802978515625) - actor/lr:np.float64(0.0001) - training/global_step:7 - training/epoch:2 - critic/score/mean:0.7646484375 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.7646484375 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:5.8681575154651e-09 - critic/advantages/max:4.448968887329102 - critic/advantages/min:-4.718453884124756 - critic/returns/mean:0.7138364911079407 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.765625 - critic/values/max:2.625 - critic/values/min:-1.0234375 - critic/vf_explained_var:-0.06371450424194336 - response_length/mean:273.6123046875 - response_length/max:1024.0 - response_length/min:67.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:273.6123046875 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:67.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:103.21923828125 - prompt_length/max:215.0 - prompt_length/min:63.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.00043513625860214233 - timing_s/generate_sequences:22.554704666137695 - timing_s/generation_timing/max:22.561742782592773 - timing_s/generation_timing/min:22.547666549682617 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:40.83173858001828 - timing_s/reward:0.2796422280371189 - timing_s/old_log_prob:27.181613486260176 - timing_s/values:39.92398789897561 - timing_s/adv:0.24520885571837425 - timing_s/update_critic:104.66625349596143 - timing_s/update_actor:103.80432103201747 - timing_s/step:317.02448769286275 - timing_s/stop_profile:8.203834295272827e-05 - timing_per_token_ms/values:0.05173169571400051 - timing_per_token_ms/gen:0.07286723590993308 - timing_per_token_ms/update_critic:0.13562179186805257 - timing_per_token_ms/adv:0.000317730531892248 - timing_per_token_ms/update_actor:0.13450493881059755 - perf/total_num_tokens:771751 - perf/time_per_step:317.02448769286275 - perf/throughput:1217.1788457358568
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:30:25 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  23%|██▎       | 7/30 [39:44<2:13:33, 348.41s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:35:40 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:8 - global_seqlen/min:388199 - global_seqlen/max:392180 - global_seqlen/minmax_diff:3981 - global_seqlen/balanced_min:390189 - global_seqlen/balanced_max:390190 - global_seqlen/mean:390189.5 - actor/entropy:0.18827484548091888 - critic/vf_loss:np.float64(0.006285405993935456) - critic/vf_clipfrac:np.float64(0.02112818977070674) - critic/vpred_mean:np.float64(0.7446048731217161) - critic/grad_norm:np.float64(3.4102650806307793) - perf/mfu/critic:np.float64(0.039668792972849226) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00104155653991711) - actor/pg_clipfrac:np.float64(0.004466829254624827) - actor/ppo_kl:np.float64(0.0015120435019326806) - actor/pg_clipfrac_lower:np.float64(0.0) - actor/grad_norm:np.float64(0.04484592564404011) - perf/mfu/actor:np.float64(0.040701961773425) - perf/max_memory_allocated_gb:np.float64(74.06899213790894) - perf/max_memory_reserved_gb:np.float64(80.615234375) - perf/cpu_memory_used_gb:np.float64(70.77636337280273) - actor/lr:np.float64(0.0001) - training/global_step:8 - training/epoch:2 - critic/score/mean:0.796875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.796875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-7.506924526445857e-10 - critic/advantages/max:3.227515697479248 - critic/advantages/min:-4.118738174438477 - critic/returns/mean:0.7410847544670105 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.55078125 - critic/values/max:1.5390625 - critic/values/min:-0.78125 - critic/vf_explained_var:0.08273839950561523 - response_length/mean:277.8984375 - response_length/max:1024.0 - response_length/min:58.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:277.8984375 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:58.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:103.14599609375 - prompt_length/max:238.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.00022836029529571533 - timing_s/generate_sequences:22.24203109741211 - timing_s/generation_timing/max:22.548677444458008 - timing_s/generation_timing/min:21.935386657714844 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:39.14202402159572 - timing_s/reward:0.47148044779896736 - timing_s/old_log_prob:27.685785211622715 - timing_s/values:43.696242190897465 - timing_s/adv:0.33408715948462486 - timing_s/update_critic:108.6532649025321 - timing_s/update_actor:105.88921604305506 - timing_s/step:325.9494366720319 - timing_s/stop_profile:0.0001945793628692627 - timing_per_token_ms/values:0.05599361616714118 - timing_per_token_ms/gen:0.06877446519214338 - timing_per_token_ms/update_critic:0.13923140538447612 - timing_per_token_ms/adv:0.00042810885413962303 - timing_per_token_ms/update_actor:0.1356894740159013 - perf/total_num_tokens:780379 - perf/time_per_step:325.9494366720319 - perf/throughput:1197.0859774567
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:35:41 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  27%|██▋       | 8/30 [45:10<2:05:08, 341.29s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:41:07 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:9 - global_seqlen/min:393408 - global_seqlen/max:396124 - global_seqlen/minmax_diff:2716 - global_seqlen/balanced_min:394766 - global_seqlen/balanced_max:394766 - global_seqlen/mean:394766.0 - actor/entropy:0.1951211541891098 - critic/vf_loss:np.float64(0.005220862874580234) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.7422797161852941) - critic/grad_norm:np.float64(2.3258945047855377) - perf/mfu/critic:np.float64(0.04178165025532592) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0009737386295682882) - actor/pg_clipfrac:np.float64(0.003524024637954426) - actor/ppo_kl:np.float64(0.0007236511819348479) - actor/pg_clipfrac_lower:np.float64(0.0) - actor/grad_norm:np.float64(0.042923822067677975) - perf/mfu/actor:np.float64(0.04105124401466469) - perf/max_memory_allocated_gb:np.float64(74.06899213790894) - perf/max_memory_reserved_gb:np.float64(80.615234375) - perf/cpu_memory_used_gb:np.float64(78.77919387817383) - actor/lr:np.float64(0.0001) - training/global_step:9 - training/epoch:2 - critic/score/mean:0.81396484375 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.81396484375 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:7.57888152236319e-09 - critic/advantages/max:2.975771903991699 - critic/advantages/min:-3.2933623790740967 - critic/returns/mean:0.7627713084220886 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.6484375 - critic/values/max:1.1953125 - critic/values/min:-0.30078125 - critic/vf_explained_var:0.1239672303199768 - response_length/mean:281.64990234375 - response_length/max:1024.0 - response_length/min:76.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:281.64990234375 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:76.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:103.86376953125 - prompt_length/max:256.0 - prompt_length/min:63.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:9.227916598320007e-05 - timing_s/generate_sequences:22.397663116455078 - timing_s/generation_timing/max:22.93757438659668 - timing_s/generation_timing/min:21.857751846313477 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:41.488385524600744 - timing_s/reward:0.30946193262934685 - timing_s/old_log_prob:27.53176012635231 - timing_s/values:39.12821331247687 - timing_s/adv:0.24062297865748405 - timing_s/update_critic:104.36084558814764 - timing_s/update_actor:106.28337651118636 - timing_s/step:319.41822512820363 - timing_s/stop_profile:8.871406316757202e-05 - timing_per_token_ms/values:0.04955874279000329 - timing_per_token_ms/gen:0.07192617705831594 - timing_per_token_ms/update_critic:0.13218064066832966 - timing_per_token_ms/adv:0.00030476659420705437 - timing_per_token_ms/update_actor:0.13461566663692714 - perf/total_num_tokens:789532 - perf/time_per_step:319.41822512820363 - perf/throughput:1235.8906566510234
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:41:08 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  30%|███       | 9/30 [50:30<1:57:04, 334.49s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:46:28 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 10}
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:46:29 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:52:18 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m validation generation end
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:52:19 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m [prompt] system
[36m(TaskRunner pid=6616)[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
[36m(TaskRunner pid=6616)[0m user
[36m(TaskRunner pid=6616)[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after "####".
[36m(TaskRunner pid=6616)[0m assistant
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m [response] Sure, let's break down the problem step by step:
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 1. **Calculate the total number of eggs laid per day:**
[36m(TaskRunner pid=6616)[0m    Janet's ducks lay 16 eggs per day.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 2. **Calculate the number of eggs eaten for breakfast:**
[36m(TaskRunner pid=6616)[0m    Janet eats 3 eggs for breakfast every morning.
[36m(TaskRunner pid=6616)[0m    \[
[36m(TaskRunner pid=6616)[0m    \text{Eggs eaten for breakfast} = 3
[36m(TaskRunner pid=6616)[0m    \]
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 3. **Calculate the number of eggs used to bake muffins:**
[36m(TaskRunner pid=6616)[0m    Janet uses 4 eggs to bake muffins for her friends.
[36m(TaskRunner pid=6616)[0m    \[
[36m(TaskRunner pid=6616)[0m    \text{Eggs used for muffins} = 4
[36m(TaskRunner pid=6616)[0m    \]
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 4. **Calculate the number of eggs left for sale at the farmers' market:**
[36m(TaskRunner pid=6616)[0m    Subtract the eggs eaten for breakfast and the eggs used for muffins from the total number of eggs laid.
[36m(TaskRunner pid=6616)[0m    \[
[36m(TaskRunner pid=6616)[0m    \text{Eggs left for sale} = 16 - 3 - 4 = 9
[36m(TaskRunner pid=6616)[0m    \]
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 5. **Calculate the total revenue from selling the eggs at the farmers' market:**
[36m(TaskRunner pid=6616)[0m    Janet sells each egg for $2.
[36m(TaskRunner pid=6616)[0m    \[
[36m(TaskRunner pid=6616)[0m    \text{Total revenue} = 9 \text{ eggs} \times 2 \text{ dollars per egg} = 18 \text{ dollars}
[36m(TaskRunner pid=6616)[0m    \]
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m So, Janet makes $18 every day at the farmers' market. The final answer is:
[36m(TaskRunner pid=6616)[0m #### 18
[36m(TaskRunner pid=6616)[0m [ground_truth] 18
[36m(TaskRunner pid=6616)[0m [score] 1.0
[36m(TaskRunner pid=6616)[0m local_global_step_folder: checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 04:52:44,077:[Rank 1] Saved model to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/actor/model_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 04:52:44,177:[Rank 1] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/actor/optim_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 04:52:44,178:[Rank 1] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/actor/extra_state_world_size_2_rank_1.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 04:52:45,615:[Rank 0] Saved model config and tokenizer class to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/actor/huggingface
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 04:53:07,788:[Rank 0] Saved model to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/critic/model_world_size_2_rank_0.pt[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 04:52:45,230:[Rank 0] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/actor/optim_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 04:52:45,231:[Rank 0] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/actor/extra_state_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 04:53:07,893:[Rank 0] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/critic/optim_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 04:53:07,894:[Rank 0] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/critic/extra_state_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 04:53:08,045:[Rank 0] Saved model config and tokenizer class to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/critic/huggingface
[36m(TaskRunner pid=6616)[0m step:10 - global_seqlen/min:399754 - global_seqlen/max:402052 - global_seqlen/minmax_diff:2298 - global_seqlen/balanced_min:400903 - global_seqlen/balanced_max:400903 - global_seqlen/mean:400903.0 - actor/entropy:0.28593331575393677 - critic/vf_loss:np.float64(0.005228328105658875) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.7689311204012483) - critic/grad_norm:np.float64(2.330414891242981) - perf/mfu/critic:np.float64(0.03865413888085507) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0011194620405774458) - actor/pg_clipfrac:np.float64(0.0055718806372624385) - actor/ppo_kl:np.float64(0.0025912103497205408) - actor/pg_clipfrac_lower:np.float64(0.0) - actor/grad_norm:np.float64(0.04406389547511935) - perf/mfu/actor:np.float64(0.03649718464504222) - perf/max_memory_allocated_gb:np.float64(74.12092018127441) - perf/max_memory_reserved_gb:np.float64(80.693359375) - perf/cpu_memory_used_gb:np.float64(80.18888664245605) - actor/lr:np.float64(0.0001) - val-core/openai/gsm8k/reward/mean@1:np.float64(0.7649734647460197) - training/global_step:10 - training/epoch:3 - critic/score/mean:0.79248046875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.79248046875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:5.385905943455782e-09 - critic/advantages/max:3.085881471633911 - critic/advantages/min:-4.477076530456543 - critic/returns/mean:0.7193611264228821 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.86328125 - critic/values/max:1.921875 - critic/values/min:-0.82421875 - critic/vf_explained_var:0.2196177840232849 - response_length/mean:287.736328125 - response_length/max:1024.0 - response_length/min:86.0 - response_length/clip_ratio:0.001953125 - response_length_non_aborted/mean:287.736328125 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:86.0 - response_length_non_aborted/clip_ratio:0.001953125 - response/aborted_ratio:0.0 - prompt_length/mean:103.7705078125 - prompt_length/max:256.0 - prompt_length/min:62.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.00047088414430618286 - timing_s/generate_sequences:23.350383758544922 - timing_s/generation_timing/max:23.500770568847656 - timing_s/generation_timing/min:23.199995040893555 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:40.39510779827833 - timing_s/reward:0.4908903166651726 - timing_s/old_log_prob:27.775541808456182 - timing_s/values:41.94248950481415 - timing_s/adv:0.35211212933063507 - timing_s/update_critic:114.6176199875772 - timing_s/update_actor:121.41161366924644 - timing_s/step:347.06740413978696 - timing_s/testing:39.24082589522004 - timing_s/save_checkpoint:28.127542175352573 - timing_s/stop_profile:0.00022799894213676453 - timing_per_token_ms/values:0.05231002200633838 - timing_per_token_ms/gen:0.0685494732561521 - timing_per_token_ms/update_critic:0.1429493169015662 - timing_per_token_ms/adv:0.00043914878328502787 - timing_per_token_ms/update_actor:0.1514226803855876 - perf/total_num_tokens:801806 - perf/time_per_step:347.06740413978696 - perf/throughput:1155.1156784476652
[36m(TaskRunner pid=6616)[0m 
Training Progress:  33%|███▎      | 10/30 [57:27<2:00:00, 360.00s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:53:23 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:11 - global_seqlen/min:405051 - global_seqlen/max:423379 - global_seqlen/minmax_diff:18328 - global_seqlen/balanced_min:414215 - global_seqlen/balanced_max:414215 - global_seqlen/mean:414215.0 - actor/entropy:0.7518265247344971 - critic/vf_loss:np.float64(0.004627460103847625) - critic/vf_clipfrac:np.float64(0.0001558699236738903) - critic/vpred_mean:np.float64(0.6634495976613835) - critic/grad_norm:np.float64(1.9339606687426567) - perf/mfu/critic:np.float64(0.043275322449370573) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0012960529772385598) - actor/pg_clipfrac:np.float64(0.0063962712732745786) - actor/ppo_kl:np.float64(0.001851528399675395) - actor/pg_clipfrac_lower:np.float64(1.839100718825648e-06) - actor/grad_norm:np.float64(0.05062260897830129) - perf/mfu/actor:np.float64(0.04416943153823151) - perf/max_memory_allocated_gb:np.float64(74.15847396850586) - perf/max_memory_reserved_gb:np.float64(80.693359375) - perf/cpu_memory_used_gb:np.float64(141.55592727661133) - actor/lr:np.float64(0.0001) - training/global_step:11 - training/epoch:3 - critic/score/mean:0.7890625 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.7890625 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-1.1254600584820196e-09 - critic/advantages/max:8.26373291015625 - critic/advantages/min:-19.14752960205078 - critic/returns/mean:0.6675209403038025 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.59375 - critic/values/max:7.21875 - critic/values/min:-3.21875 - critic/vf_explained_var:0.3467410206794739 - response_length/mean:301.21142578125 - response_length/max:1024.0 - response_length/min:68.0 - response_length/clip_ratio:0.0283203125 - response_length_non_aborted/mean:301.21142578125 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:68.0 - response_length_non_aborted/clip_ratio:0.0283203125 - response/aborted_ratio:0.0 - prompt_length/mean:103.29541015625 - prompt_length/max:232.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.0003064274787902832 - timing_s/generate_sequences:23.601791381835938 - timing_s/generation_timing/max:24.15570640563965 - timing_s/generation_timing/min:23.047876358032227 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:40.790009342134 - timing_s/reward:0.48744483664631844 - timing_s/old_log_prob:28.79480630159378 - timing_s/values:41.2506648004055 - timing_s/adv:0.30662525445222855 - timing_s/update_critic:106.02686460316181 - timing_s/update_actor:103.86727008596063 - timing_s/step:321.6251289844513 - timing_s/stop_profile:8.212774991989136e-05 - timing_per_token_ms/values:0.049793784387824565 - timing_per_token_ms/gen:0.06612297889241847 - timing_per_token_ms/update_critic:0.12798530304692227 - timing_per_token_ms/adv:0.0003701281393144002 - timing_per_token_ms/update_actor:0.12537845090829716 - perf/total_num_tokens:828430 - perf/time_per_step:321.6251289844513 - perf/throughput:1287.8813334887925
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:53:24 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  37%|███▋      | 11/30 [1:02:49<1:50:17, 348.30s/it]
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 04:53:07,894:[Rank 1] Saved model to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/critic/model_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 04:53:07,995:[Rank 1] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/critic/optim_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 04:53:07,996:[Rank 1] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_10/critic/extra_state_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m WARNING 10-22 04:58:42 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:12 - global_seqlen/min:440474 - global_seqlen/max:457325 - global_seqlen/minmax_diff:16851 - global_seqlen/balanced_min:448899 - global_seqlen/balanced_max:448900 - global_seqlen/mean:448899.5 - actor/entropy:1.4977030754089355 - critic/vf_loss:np.float64(0.004127839605189365) - critic/vf_clipfrac:np.float64(0.00025372818311097944) - critic/vpred_mean:np.float64(0.5855529628461227) - critic/grad_norm:np.float64(1.8497385382652283) - perf/mfu/critic:np.float64(0.04750977888430394) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0026586680352238545) - actor/pg_clipfrac:np.float64(0.015180210939774952) - actor/ppo_kl:np.float64(0.006125739195780966) - actor/pg_clipfrac_lower:np.float64(6.549989279847068e-06) - actor/grad_norm:np.float64(0.05493663065135479) - perf/mfu/actor:np.float64(0.046333003573002046) - perf/max_memory_allocated_gb:np.float64(74.3552074432373) - perf/max_memory_reserved_gb:np.float64(80.734375) - perf/cpu_memory_used_gb:np.float64(104.9256820678711) - actor/lr:np.float64(0.0001) - training/global_step:12 - training/epoch:3 - critic/score/mean:0.75244140625 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.75244140625 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:1.1311301229000037e-08 - critic/advantages/max:10.606541633605957 - critic/advantages/min:-16.214271545410156 - critic/returns/mean:0.5635042190551758 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.55859375 - critic/values/max:5.8125 - critic/values/min:-3.8125 - critic/vf_explained_var:0.47644543647766113 - response_length/mean:334.61181640625 - response_length/max:1024.0 - response_length/min:80.0 - response_length/clip_ratio:0.07080078125 - response_length_non_aborted/mean:334.61181640625 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:80.0 - response_length_non_aborted/clip_ratio:0.07080078125 - response/aborted_ratio:0.0 - prompt_length/mean:103.7666015625 - prompt_length/max:215.0 - prompt_length/min:56.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:6.034970283508301e-05 - timing_s/generate_sequences:25.121601104736328 - timing_s/generation_timing/max:25.156997680664062 - timing_s/generation_timing/min:25.08620262145996 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:39.82593863084912 - timing_s/reward:0.31194794550538063 - timing_s/old_log_prob:29.15873995423317 - timing_s/values:39.36112920567393 - timing_s/adv:0.3137941136956215 - timing_s/update_critic:105.10746462270617 - timing_s/update_actor:107.8244796693325 - timing_s/step:321.94924199581146 - timing_s/stop_profile:0.00011062994599342346 - timing_per_token_ms/values:0.04384180557750001 - timing_per_token_ms/gen:0.058115876797024776 - timing_per_token_ms/update_critic:0.11707237880940631 - timing_per_token_ms/adv:0.0003495148843957517 - timing_per_token_ms/update_actor:0.12009868541770764 - perf/total_num_tokens:897799 - perf/time_per_step:321.94924199581146 - perf/throughput:1394.317617327517
[36m(WorkerDict pid=7191)[0m WARNING 10-22 04:58:43 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  40%|████      | 12/30 [1:08:11<1:42:05, 340.31s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:04:08 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:13 - global_seqlen/min:513093 - global_seqlen/max:524504 - global_seqlen/minmax_diff:11411 - global_seqlen/balanced_min:518798 - global_seqlen/balanced_max:518799 - global_seqlen/mean:518798.5 - actor/entropy:3.2136292457580566 - critic/vf_loss:np.float64(0.003308801944285733) - critic/vf_clipfrac:np.float64(0.0009022866655641337) - critic/vpred_mean:np.float64(0.48531585780438036) - critic/grad_norm:np.float64(1.7691060323268175) - perf/mfu/critic:np.float64(0.05375570170192644) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0015386280219971127) - actor/pg_clipfrac:np.float64(0.017364080370839474) - actor/ppo_kl:np.float64(0.008324259578785131) - actor/pg_clipfrac_lower:np.float64(2.8950665523552743e-05) - actor/grad_norm:np.float64(0.06599052902311087) - perf/mfu/actor:np.float64(0.054551418360102855) - perf/max_memory_allocated_gb:np.float64(74.55418014526367) - perf/max_memory_reserved_gb:np.float64(80.734375) - perf/cpu_memory_used_gb:np.float64(118.11524200439453) - actor/lr:np.float64(0.0001) - training/global_step:13 - training/epoch:4 - critic/score/mean:0.68115234375 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.68115234375 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:1.9647979243586633e-08 - critic/advantages/max:11.9363431930542 - critic/advantages/min:-19.716764450073242 - critic/returns/mean:0.40986451506614685 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.54296875 - critic/values/max:6.46875 - critic/values/min:-3.703125 - critic/vf_explained_var:0.573067843914032 - response_length/mean:402.5244140625 - response_length/max:1024.0 - response_length/min:66.0 - response_length/clip_ratio:0.15673828125 - response_length_non_aborted/mean:402.5244140625 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:66.0 - response_length_non_aborted/clip_ratio:0.15673828125 - response/aborted_ratio:0.0 - prompt_length/mean:104.11474609375 - prompt_length/max:256.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.00038810446858406067 - timing_s/generate_sequences:29.530372619628906 - timing_s/generation_timing/max:29.770286560058594 - timing_s/generation_timing/min:29.29045867919922 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:45.46132205054164 - timing_s/reward:0.3270512633025646 - timing_s/old_log_prob:27.626318223774433 - timing_s/values:41.816661577671766 - timing_s/adv:0.3380294367671013 - timing_s/update_critic:107.99051091074944 - timing_s/update_actor:106.50348301976919 - timing_s/step:330.1363955438137 - timing_s/stop_profile:9.60417091846466e-05 - timing_per_token_ms/values:0.040301448035867264 - timing_per_token_ms/gen:0.05514674484823761 - timing_per_token_ms/update_critic:0.10407750881194668 - timing_per_token_ms/adv:0.00032578104675235305 - timing_per_token_ms/update_actor:0.10264436290753462 - perf/total_num_tokens:1037597 - perf/time_per_step:330.1363955438137 - perf/throughput:1571.4671481325609
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:04:09 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  43%|████▎     | 13/30 [1:13:44<1:35:49, 338.23s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:09:36 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:14 - global_seqlen/min:592003 - global_seqlen/max:606115 - global_seqlen/minmax_diff:14112 - global_seqlen/balanced_min:599059 - global_seqlen/balanced_max:599059 - global_seqlen/mean:599059.0 - actor/entropy:4.324804782867432 - critic/vf_loss:np.float64(0.0031746838578783354) - critic/vf_clipfrac:np.float64(5.4632939793464175e-05) - critic/vpred_mean:np.float64(0.3548851035234293) - critic/grad_norm:np.float64(3.3484383672475815) - perf/mfu/critic:np.float64(0.06322386286804069) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0008971541788014292) - actor/pg_clipfrac:np.float64(0.03422500371107162) - actor/ppo_kl:np.float64(0.005860655373798096) - actor/pg_clipfrac_lower:np.float64(4.8823131294284394e-05) - actor/grad_norm:np.float64(0.09291984047740698) - perf/mfu/actor:np.float64(0.06230394510443785) - perf/max_memory_allocated_gb:np.float64(74.61537742614746) - perf/max_memory_reserved_gb:np.float64(80.96484375) - perf/cpu_memory_used_gb:np.float64(129.4596176147461) - actor/lr:np.float64(0.0001) - training/global_step:14 - training/epoch:4 - critic/score/mean:0.58251953125 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.58251953125 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:4.645851259255096e-09 - critic/advantages/max:10.588851928710938 - critic/advantages/min:-15.976775169372559 - critic/returns/mean:0.28861773014068604 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.34375 - critic/values/max:4.125 - critic/values/min:-2.640625 - critic/vf_explained_var:0.6841157674789429 - response_length/mean:480.7109375 - response_length/max:1024.0 - response_length/min:37.0 - response_length/clip_ratio:0.26318359375 - response_length_non_aborted/mean:480.7109375 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:37.0 - response_length_non_aborted/clip_ratio:0.26318359375 - response/aborted_ratio:0.0 - prompt_length/mean:104.3076171875 - prompt_length/max:222.0 - prompt_length/min:65.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:5.971640348434448e-05 - timing_s/generate_sequences:32.768428802490234 - timing_s/generation_timing/max:33.8782844543457 - timing_s/generation_timing/min:31.658571243286133 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:47.94397494569421 - timing_s/reward:0.40013260021805763 - timing_s/old_log_prob:26.87314895913005 - timing_s/values:38.990734186023474 - timing_s/adv:0.23512057960033417 - timing_s/update_critic:106.57482302933931 - timing_s/update_actor:108.1400197185576 - timing_s/step:329.47371627762914 - timing_s/stop_profile:8.736923336982727e-05 - timing_per_token_ms/values:0.032543317257585205 - timing_per_token_ms/gen:0.04869900430849308 - timing_per_token_ms/update_critic:0.08895185868949412 - timing_per_token_ms/adv:0.00019624158855833412 - timing_per_token_ms/update_actor:0.09025823810222165 - perf/total_num_tokens:1198118 - perf/time_per_step:329.47371627762914 - perf/throughput:1818.2300147281137
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:09:38 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  47%|████▋     | 14/30 [1:19:14<1:29:29, 335.62s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:15:07 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 15}
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:15:08 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:21:02 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m validation generation end
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:21:02 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m [prompt] system
[36m(TaskRunner pid=6616)[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
[36m(TaskRunner pid=6616)[0m user
[36m(TaskRunner pid=6616)[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after "####".
[36m(TaskRunner pid=6616)[0m assistant
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m [response] Sure, let's break this down step by step:
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 1. **Calculate the total number of eggs laid per day:**
[36m(TaskRunner pid=6616)[0m    - Janet’s ducks lay 16 eggs per day.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 2. **Calculate the number of eggs eaten for breakfast:**
[36m(TaskRunner pid=6616)[0m    - Janet eats 3 eggs for breakfast every morning.
[36m(TaskRunner pid=6616)[0m    - Eggs eaten for breakfast per day = 3 eggs.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 3. **Calculate the number of eggs used to bake muffins:**
[36m(TaskRunner pid=6616)[0m    - Janet uses 4 eggs to bake muffins.
[36m(TaskRunner pid=6616)[0m    - Eggs used for muffins per day = 4 eggs.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 4. **Calculate the number of eggs left for sale at the farmers' market:**
[36m(TaskRunner pid=6616)[0m    - Total eggs laid per day = 16 eggs.
[36m(TaskRunner pid=6616)[0m    - Eggs eaten for breakfast per day = 3 eggs.
[36m(TaskRunner pid=6616)[0m    - Eggs used for muffins per day = 4 eggs.
[36m(TaskRunner pid=6616)[0m    - Eggs left for sale per day = 16 eggs - 3 eggs - 4 eggs = 9 eggs.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 5. **Calculate the revenue from selling the eggs at the farmers' market:**
[36m(TaskRunner pid=6616)[0m    - Janet sells each egg for $2.
[36m(TaskRunner pid=6616)[0m    - Revenue from selling eggs per day = 9 eggs * $2 per egg = $18.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m So, Janet makes $18 every day at the farmers' market. The final answer is:
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m #### 18
[36m(TaskRunner pid=6616)[0m [ground_truth] 18
[36m(TaskRunner pid=6616)[0m [score] 1.0
[36m(TaskRunner pid=6616)[0m step:15 - global_seqlen/min:820468 - global_seqlen/max:825231 - global_seqlen/minmax_diff:4763 - global_seqlen/balanced_min:822849 - global_seqlen/balanced_max:822850 - global_seqlen/mean:822849.5 - actor/entropy:5.8750319480896 - critic/vf_loss:np.float64(0.0014297732246859596) - critic/vf_clipfrac:np.float64(0.0005667676808798205) - critic/vpred_mean:np.float64(0.09886542947606358) - critic/grad_norm:np.float64(2.0349724739789963) - perf/mfu/critic:np.float64(0.09203189606845208) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0005928792591873844) - actor/pg_clipfrac:np.float64(0.030373868024980766) - actor/ppo_kl:np.float64(0.009369693839062165) - actor/pg_clipfrac_lower:np.float64(7.805921035242136e-05) - actor/grad_norm:np.float64(0.11381245963275433) - perf/mfu/actor:np.float64(0.08931880711136667) - perf/max_memory_allocated_gb:np.float64(74.93496894836426) - perf/max_memory_reserved_gb:np.float64(81.8828125) - perf/cpu_memory_used_gb:np.float64(135.14959335327148) - actor/lr:np.float64(0.0001) - val-core/openai/gsm8k/reward/mean@1:np.float64(0.7422289613343442) - training/global_step:15 - training/epoch:4 - critic/score/mean:0.302734375 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.302734375 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-3.15606740741714e-08 - critic/advantages/max:6.634742259979248 - critic/advantages/min:-11.695237159729004 - critic/returns/mean:0.09249431639909744 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.259765625 - critic/values/max:2.28125 - critic/values/min:-1.03125 - critic/vf_explained_var:0.6109805107116699 - response_length/mean:700.66064453125 - response_length/max:1024.0 - response_length/min:9.0 - response_length/clip_ratio:0.546875 - response_length_non_aborted/mean:700.66064453125 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:9.0 - response_length_non_aborted/clip_ratio:0.546875 - response/aborted_ratio:0.0 - prompt_length/mean:102.9033203125 - prompt_length/max:212.0 - prompt_length/min:63.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:6.231293082237244e-05 - timing_s/generate_sequences:55.40013885498047 - timing_s/generation_timing/max:55.67888641357422 - timing_s/generation_timing/min:55.121395111083984 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:69.89587267115712 - timing_s/reward:0.5015979781746864 - timing_s/old_log_prob:26.840237494558096 - timing_s/values:46.46748514845967 - timing_s/adv:0.3263179063796997 - timing_s/update_critic:101.43504621088505 - timing_s/update_actor:104.57311882451177 - timing_s/step:350.13911287486553 - timing_s/testing:36.89184695482254 - timing_s/stop_profile:5.7660043239593506e-05 - timing_per_token_ms/values:0.028235713303866424 - timing_per_token_ms/gen:0.04870952057046964 - timing_per_token_ms/update_critic:0.061636451265319504 - timing_per_token_ms/adv:0.00019828529176945463 - timing_per_token_ms/update_actor:0.06354328393254889 - perf/total_num_tokens:1645699 - perf/time_per_step:350.13911287486553 - perf/throughput:2350.0645022027975
[36m(TaskRunner pid=6616)[0m 
Training Progress:  50%|█████     | 15/30 [1:25:41<1:27:47, 351.15s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:21:36 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:16 - global_seqlen/min:926963 - global_seqlen/max:936822 - global_seqlen/minmax_diff:9859 - global_seqlen/balanced_min:931892 - global_seqlen/balanced_max:931893 - global_seqlen/mean:931892.5 - actor/entropy:6.004167556762695 - critic/vf_loss:np.float64(0.0006902156873138665) - critic/vf_clipfrac:np.float64(4.76837158203125e-07) - critic/vpred_mean:np.float64(0.031526227509743876) - critic/grad_norm:np.float64(0.9280289374291897) - perf/mfu/critic:np.float64(0.10304078651650739) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00047257845551484934) - actor/pg_clipfrac:np.float64(0.027603558992041144) - actor/ppo_kl:np.float64(0.004205107234934502) - actor/pg_clipfrac_lower:np.float64(2.729415530211554e-05) - actor/grad_norm:np.float64(0.08402366703376174) - perf/mfu/actor:np.float64(0.1043554895033397) - perf/max_memory_allocated_gb:np.float64(74.95887565612793) - perf/max_memory_reserved_gb:np.float64(81.8828125) - perf/cpu_memory_used_gb:np.float64(87.84555435180664) - actor/lr:np.float64(0.0001) - training/global_step:16 - training/epoch:5 - critic/score/mean:0.1728515625 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.1728515625 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-2.578401669950381e-08 - critic/advantages/max:8.512028694152832 - critic/advantages/min:-13.509535789489746 - critic/returns/mean:0.04683440923690796 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:-0.0030670166015625 - critic/values/max:1.8671875 - critic/values/min:-1.03125 - critic/vf_explained_var:0.5490041375160217 - response_length/mean:806.56298828125 - response_length/max:1024.0 - response_length/min:10.0 - response_length/clip_ratio:0.6904296875 - response_length_non_aborted/mean:806.56298828125 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:10.0 - response_length_non_aborted/clip_ratio:0.6904296875 - response/aborted_ratio:0.0 - prompt_length/mean:103.48828125 - prompt_length/max:256.0 - prompt_length/min:63.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.0004396587610244751 - timing_s/generate_sequences:57.81878662109375 - timing_s/generation_timing/max:59.06905746459961 - timing_s/generation_timing/min:56.56851577758789 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:72.11211714148521 - timing_s/reward:0.8528617359697819 - timing_s/old_log_prob:28.002501238137484 - timing_s/values:40.26691281422973 - timing_s/adv:0.4350954480469227 - timing_s/update_critic:102.92368970066309 - timing_s/update_actor:101.62486844882369 - timing_s/step:346.3458045460284 - timing_s/stop_profile:0.00013921037316322327 - timing_per_token_ms/values:0.021604913020670156 - timing_per_token_ms/gen:0.04365560434780661 - timing_per_token_ms/update_critic:0.05522294132674267 - timing_per_token_ms/adv:0.0002334472313313621 - timing_per_token_ms/update_actor:0.05452606843000866 - perf/total_num_tokens:1863785 - perf/time_per_step:346.3458045460284 - perf/throughput:2690.6418029849533
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:21:37 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  53%|█████▎    | 16/30 [1:31:30<1:21:48, 350.64s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:27:25 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:17 - global_seqlen/min:893291 - global_seqlen/max:896580 - global_seqlen/minmax_diff:3289 - global_seqlen/balanced_min:894935 - global_seqlen/balanced_max:894936 - global_seqlen/mean:894935.5 - actor/entropy:6.584718227386475 - critic/vf_loss:np.float64(0.0006034528726672761) - critic/vf_clipfrac:np.float64(1.2857965430157492e-06) - critic/vpred_mean:np.float64(0.08637446437901986) - critic/grad_norm:np.float64(0.9686988033354282) - perf/mfu/critic:np.float64(0.09713468009116047) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0009470946388887569) - actor/pg_clipfrac:np.float64(0.029979107639292124) - actor/ppo_kl:np.float64(0.008684256521064526) - actor/pg_clipfrac_lower:np.float64(1.8856490555663186e-06) - actor/grad_norm:np.float64(0.07470468850806355) - perf/mfu/actor:np.float64(0.09091092226423719) - perf/max_memory_allocated_gb:np.float64(74.95887565612793) - perf/max_memory_reserved_gb:np.float64(81.982421875) - perf/cpu_memory_used_gb:np.float64(93.32161331176758) - actor/lr:np.float64(0.0001) - training/global_step:17 - training/epoch:5 - critic/score/mean:0.23486328125 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.23486328125 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:3.995874919837661e-08 - critic/advantages/max:8.37948226928711 - critic/advantages/min:-9.953999519348145 - critic/returns/mean:0.06551816314458847 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.1513671875 - critic/values/max:1.40625 - critic/values/min:-0.77734375 - critic/vf_explained_var:0.7124896049499512 - response_length/mean:770.53271484375 - response_length/max:1024.0 - response_length/min:20.0 - response_length/clip_ratio:0.658203125 - response_length_non_aborted/mean:770.53271484375 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:20.0 - response_length_non_aborted/clip_ratio:0.658203125 - response/aborted_ratio:0.0 - prompt_length/mean:103.427734375 - prompt_length/max:199.0 - prompt_length/min:56.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:7.518753409385681e-05 - timing_s/generate_sequences:56.125465393066406 - timing_s/generation_timing/max:56.439208984375 - timing_s/generation_timing/min:55.81172561645508 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:72.25854628533125 - timing_s/reward:0.6386459022760391 - timing_s/old_log_prob:27.161777589470148 - timing_s/values:38.98387319967151 - timing_s/adv:0.2680398039519787 - timing_s/update_critic:104.79482087120414 - timing_s/update_actor:111.95861466228962 - timing_s/step:356.1407751701772 - timing_s/stop_profile:9.955838322639465e-05 - timing_per_token_ms/values:0.02178026975110022 - timing_per_token_ms/gen:0.04578974081657136 - timing_per_token_ms/update_critic:0.058548812105008764 - timing_per_token_ms/adv:0.0001497536995414634 - timing_per_token_ms/update_actor:0.06255121998305443 - perf/total_num_tokens:1789871 - perf/time_per_step:356.1407751701772 - perf/throughput:2512.8700850734285
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:27:26 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  57%|█████▋    | 17/30 [1:37:27<1:16:20, 352.33s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:33:21 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:18 - global_seqlen/min:896101 - global_seqlen/max:897816 - global_seqlen/minmax_diff:1715 - global_seqlen/balanced_min:896958 - global_seqlen/balanced_max:896959 - global_seqlen/mean:896958.5 - actor/entropy:6.781833171844482 - critic/vf_loss:np.float64(0.00040813624897850787) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.08047227973679583) - critic/grad_norm:np.float64(0.6944102086126804) - perf/mfu/critic:np.float64(0.08906392900319265) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00027792379590962923) - actor/pg_clipfrac:np.float64(0.030752851185525287) - actor/ppo_kl:np.float64(0.009086284895452934) - actor/pg_clipfrac_lower:np.float64(1.9024371511022764e-05) - actor/grad_norm:np.float64(0.08039034344255924) - perf/mfu/actor:np.float64(0.10180890817232327) - perf/max_memory_allocated_gb:np.float64(74.95887565612793) - perf/max_memory_reserved_gb:np.float64(81.982421875) - perf/cpu_memory_used_gb:np.float64(166.0319938659668) - actor/lr:np.float64(0.0001) - training/global_step:18 - training/epoch:5 - critic/score/mean:0.25244140625 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.25244140625 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-1.1689299306283374e-08 - critic/advantages/max:8.412435531616211 - critic/advantages/min:-12.162453651428223 - critic/returns/mean:0.06983625143766403 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.0042724609375 - critic/values/max:1.328125 - critic/values/min:-0.486328125 - critic/vf_explained_var:0.8220502138137817 - response_length/mean:772.51025390625 - response_length/max:1024.0 - response_length/min:6.0 - response_length/clip_ratio:0.671875 - response_length_non_aborted/mean:772.51025390625 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:6.0 - response_length_non_aborted/clip_ratio:0.671875 - response/aborted_ratio:0.0 - prompt_length/mean:103.42578125 - prompt_length/max:217.0 - prompt_length/min:65.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.00010683387517929077 - timing_s/generate_sequences:55.98505401611328 - timing_s/generation_timing/max:58.023353576660156 - timing_s/generation_timing/min:53.946754455566406 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:73.08265124261379 - timing_s/reward:0.8654263019561768 - timing_s/old_log_prob:27.66735314950347 - timing_s/values:43.14839965477586 - timing_s/adv:0.3129314072430134 - timing_s/update_critic:114.49416087567806 - timing_s/update_actor:100.2098993845284 - timing_s/step:359.8907017558813 - timing_s/stop_profile:8.395686745643616e-05 - timing_per_token_ms/values:0.02405261762655455 - timing_per_token_ms/gen:0.046193417008530926 - timing_per_token_ms/update_critic:0.06382355531258027 - timing_per_token_ms/adv:0.00017444029308101398 - timing_per_token_ms/update_actor:0.055860945285946005 - perf/total_num_tokens:1793917 - perf/time_per_step:359.8907017558813 - perf/throughput:2492.308069154893
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:33:21 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  60%|██████    | 18/30 [1:43:27<1:10:55, 354.65s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:39:22 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:19 - global_seqlen/min:939254 - global_seqlen/max:956320 - global_seqlen/minmax_diff:17066 - global_seqlen/balanced_min:947787 - global_seqlen/balanced_max:947787 - global_seqlen/mean:947787.0 - actor/entropy:7.623925685882568 - critic/vf_loss:np.float64(0.0002595771869522423) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.05072691689929343) - critic/grad_norm:np.float64(0.4252798091620207) - perf/mfu/critic:np.float64(0.09762677978391505) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0005410990531231619) - actor/pg_clipfrac:np.float64(0.01650745779056706) - actor/ppo_kl:np.float64(0.0025767322885030808) - actor/pg_clipfrac_lower:np.float64(1.3405504319052852e-05) - actor/grad_norm:np.float64(0.07715269830077887) - perf/mfu/actor:np.float64(0.10409456969663589) - perf/max_memory_allocated_gb:np.float64(74.97313690185547) - perf/max_memory_reserved_gb:np.float64(81.984375) - perf/cpu_memory_used_gb:np.float64(80.66540908813477) - actor/lr:np.float64(0.0001) - training/global_step:19 - training/epoch:6 - critic/score/mean:0.19091796875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.19091796875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-2.6193704982802046e-08 - critic/advantages/max:9.691020011901855 - critic/advantages/min:-13.756911277770996 - critic/returns/mean:0.048532966524362564 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.016845703125 - critic/values/max:1.2421875 - critic/values/min:-0.294921875 - critic/vf_explained_var:0.8427911996841431 - response_length/mean:822.32080078125 - response_length/max:1024.0 - response_length/min:5.0 - response_length/clip_ratio:0.73486328125 - response_length_non_aborted/mean:822.32080078125 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:5.0 - response_length_non_aborted/clip_ratio:0.73486328125 - response/aborted_ratio:0.0 - prompt_length/mean:103.25244140625 - prompt_length/max:222.0 - prompt_length/min:62.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.0004544258117675781 - timing_s/generate_sequences:57.36880111694336 - timing_s/generation_timing/max:58.30791473388672 - timing_s/generation_timing/min:56.4296875 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:71.4493056833744 - timing_s/reward:0.5825776532292366 - timing_s/old_log_prob:27.43918825685978 - timing_s/values:39.12423297390342 - timing_s/adv:0.3524927645921707 - timing_s/update_critic:110.53518594801426 - timing_s/update_actor:103.69142520427704 - timing_s/step:353.26645819842815 - timing_s/stop_profile:0.00019338726997375488 - timing_per_token_ms/values:0.020639781392814745 - timing_per_token_ms/gen:0.04242548195006773 - timing_per_token_ms/update_critic:0.05831225050987947 - timing_per_token_ms/adv:0.00018595568655835684 - timing_per_token_ms/update_actor:0.05470186086339918 - perf/total_num_tokens:1895574 - perf/time_per_step:353.26645819842815 - perf/throughput:2682.9238327167545
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:39:22 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  63%|██████▎   | 19/30 [1:49:23<1:05:05, 355.01s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:45:16 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 20}
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:45:17 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:51:11 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m validation generation end
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:51:13 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m [prompt] system
[36m(TaskRunner pid=6616)[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
[36m(TaskRunner pid=6616)[0m user
[36m(TaskRunner pid=6616)[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after "####".
[36m(TaskRunner pid=6616)[0m assistant
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m [response] To determine how much Janet makes every day at the farmers' market, we need to follow these steps:
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 1. **Calculate the total number of eggs laid per day:**
[36m(TaskRunner pid=6616)[0m    - Janet's ducks lay 16 eggs per day.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 2. **Calculate the number of eggs Janet eats for breakfast:**
[36m(TaskRunner pid=6616)[0m    - Janet eats 3 eggs for breakfast every morning.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 3. **Calculate the number of eggs she uses to bake muffins:**
[36m(TaskRunner pid=6616)[0m    - Janet uses 4 eggs to bake muffins.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 4. **Calculate the number of eggs left after breakfast and muffins:**
[36m(TaskRunner pid=6616)[0m    - Subtract the eggs eaten for breakfast and the eggs used to bake muffins from the total number of eggs laid.
[36m(TaskRunner pid=6616)[0m    - Number of eggs left = 16 - 3 - 4 = 9 eggs.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 5. **Calculate the revenue from selling the eggs:**
[36m(TaskRunner pid=6616)[0m    - Janet sells each egg for $2.
[36m(TaskRunner pid=6616)[0m    - Revenue from selling the eggs = 9 eggs * $2/egg = $18.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m Therefore, Janet makes $18 every day at the farmers' market. The final answer is:
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m #### 18
[36m(TaskRunner pid=6616)[0m [ground_truth] 18
[36m(TaskRunner pid=6616)[0m [score] 1.0
[36m(TaskRunner pid=6616)[0m local_global_step_folder: checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 05:51:38,838:[Rank 0] Saved model to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/actor/model_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 05:51:38,937:[Rank 0] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/actor/optim_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 05:51:38,938:[Rank 0] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/actor/extra_state_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 05:51:39,276:[Rank 0] Saved model config and tokenizer class to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/actor/huggingface
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 05:51:55,579:[Rank 0] Saved model to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/critic/model_world_size_2_rank_0.pt[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 05:51:39,113:[Rank 1] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/actor/optim_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 05:51:39,114:[Rank 1] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/actor/extra_state_world_size_2_rank_1.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 05:51:55,671:[Rank 0] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/critic/optim_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 05:51:55,672:[Rank 0] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/critic/extra_state_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 05:51:55,809:[Rank 0] Saved model config and tokenizer class to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/critic/huggingface
[36m(TaskRunner pid=6616)[0m step:20 - global_seqlen/min:985368 - global_seqlen/max:988870 - global_seqlen/minmax_diff:3502 - global_seqlen/balanced_min:987119 - global_seqlen/balanced_max:987119 - global_seqlen/mean:987119.0 - actor/entropy:8.170903205871582 - critic/vf_loss:np.float64(0.00018543999931353028) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.038117508123718835) - critic/grad_norm:np.float64(0.2750054949428886) - perf/mfu/critic:np.float64(0.10419449788572287) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0005339118755784966) - actor/pg_clipfrac:np.float64(0.010369391197571076) - actor/ppo_kl:np.float64(0.0005644376530131723) - actor/pg_clipfrac_lower:np.float64(6.451003571328329e-06) - actor/grad_norm:np.float64(0.05954710626974702) - perf/mfu/actor:np.float64(0.11103375353433961) - perf/max_memory_allocated_gb:np.float64(74.97313690185547) - perf/max_memory_reserved_gb:np.float64(81.984375) - perf/cpu_memory_used_gb:np.float64(83.21570205688477) - actor/lr:np.float64(0.0001) - val-core/openai/gsm8k/reward/mean@1:np.float64(0.6967399545109931) - training/global_step:20 - training/epoch:6 - critic/score/mean:0.1396484375 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.1396484375 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:8.848297206043299e-09 - critic/advantages/max:11.038972854614258 - critic/advantages/min:-15.43397045135498 - critic/returns/mean:0.03393985331058502 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.0595703125 - critic/values/max:1.28125 - critic/values/min:-0.28515625 - critic/vf_explained_var:0.8386526703834534 - response_length/mean:859.71826171875 - response_length/max:1024.0 - response_length/min:5.0 - response_length/clip_ratio:0.7841796875 - response_length_non_aborted/mean:859.71826171875 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:5.0 - response_length_non_aborted/clip_ratio:0.7841796875 - response/aborted_ratio:0.0 - prompt_length/mean:104.26513671875 - prompt_length/max:256.0 - prompt_length/min:56.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.0001178644597530365 - timing_s/generate_sequences:58.81622314453125 - timing_s/generation_timing/max:60.13963317871094 - timing_s/generation_timing/min:57.4928092956543 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:74.76066724583507 - timing_s/reward:0.75701092928648 - timing_s/old_log_prob:27.57763023674488 - timing_s/values:39.88945725560188 - timing_s/adv:0.24867798388004303 - timing_s/update_critic:107.94806700199842 - timing_s/update_actor:101.36348066478968 - timing_s/step:352.6566901728511 - timing_s/testing:37.44705060869455 - timing_s/save_checkpoint:21.898642655462027 - timing_s/stop_profile:8.882209658622742e-05 - timing_per_token_ms/values:0.020204989092298842 - timing_per_token_ms/gen:0.0424606916929403 - timing_per_token_ms/update_critic:0.0546783452663754 - timing_per_token_ms/adv:0.00012596150204790052 - timing_per_token_ms/update_actor:0.05134309068348886 - perf/total_num_tokens:1974238 - perf/time_per_step:352.6566901728511 - perf/throughput:2799.0933605035925
[36m(TaskRunner pid=6616)[0m 
Training Progress:  67%|██████▋   | 20/30 [1:56:15<1:02:01, 372.18s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:52:07 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:21 - global_seqlen/min:985437 - global_seqlen/max:985686 - global_seqlen/minmax_diff:249 - global_seqlen/balanced_min:985561 - global_seqlen/balanced_max:985562 - global_seqlen/mean:985561.5 - actor/entropy:7.9532084465026855 - critic/vf_loss:np.float64(0.00014256412040936084) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.04111752896778853) - critic/grad_norm:np.float64(0.1696002942044288) - perf/mfu/critic:np.float64(0.10834563424120239) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00047354447782765874) - actor/pg_clipfrac:np.float64(0.004328152091602533) - actor/ppo_kl:np.float64(0.0019513177524750347) - actor/pg_clipfrac_lower:np.float64(6.486350969225896e-06) - actor/grad_norm:np.float64(0.07070398004725575) - perf/mfu/actor:np.float64(0.10655039865178399) - perf/max_memory_allocated_gb:np.float64(74.97313690185547) - perf/max_memory_reserved_gb:np.float64(81.984375) - perf/cpu_memory_used_gb:np.float64(105.23741912841797) - actor/lr:np.float64(0.0001) - training/global_step:21 - training/epoch:6 - critic/score/mean:0.14501953125 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.14501953125 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:2.1124419991025434e-09 - critic/advantages/max:12.844822883605957 - critic/advantages/min:-18.168569564819336 - critic/returns/mean:0.03457215800881386 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.049072265625 - critic/values/max:1.2578125 - critic/values/min:-0.23046875 - critic/vf_explained_var:0.8734846115112305 - response_length/mean:858.82421875 - response_length/max:1024.0 - response_length/min:3.0 - response_length/clip_ratio:0.7841796875 - response_length_non_aborted/mean:858.82421875 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.7841796875 - response/aborted_ratio:0.0 - prompt_length/mean:103.63818359375 - prompt_length/max:189.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:5.513429641723633e-05 - timing_s/generate_sequences:58.4831428527832 - timing_s/generation_timing/max:59.08478927612305 - timing_s/generation_timing/min:57.88149642944336 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:72.35305044800043 - timing_s/reward:1.1047513782978058 - timing_s/old_log_prob:27.169230606406927 - timing_s/values:38.98487363010645 - timing_s/adv:0.24309562146663666 - timing_s/update_critic:103.62131848186255 - timing_s/update_actor:105.35002698004246 - timing_s/step:348.91361351683736 - timing_s/stop_profile:8.15168023109436e-05 - timing_per_token_ms/values:0.01977800148956024 - timing_per_token_ms/gen:0.041136052224380416 - timing_per_token_ms/update_critic:0.052569686661797635 - timing_per_token_ms/adv:0.0001233284891235284 - timing_per_token_ms/update_actor:0.053446703721707095 - perf/total_num_tokens:1971123 - perf/time_per_step:348.91361351683736 - perf/throughput:2824.6576281909397
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:52:09 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  70%|███████   | 21/30 [2:02:04<54:47, 365.23s/it]  
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 05:51:55,716:[Rank 1] Saved model to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/critic/model_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 05:51:55,811:[Rank 1] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/critic/optim_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 05:51:55,812:[Rank 1] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_20/critic/extra_state_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m WARNING 10-22 05:58:00 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:22 - global_seqlen/min:984633 - global_seqlen/max:988002 - global_seqlen/minmax_diff:3369 - global_seqlen/balanced_min:986317 - global_seqlen/balanced_max:986318 - global_seqlen/mean:986317.5 - actor/entropy:7.773970127105713 - critic/vf_loss:np.float64(0.00012549659103910926) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.037835766114767466) - critic/grad_norm:np.float64(0.1358770753722638) - perf/mfu/critic:np.float64(0.10409933435359832) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0002487136114268651) - actor/pg_clipfrac:np.float64(0.006889170343299611) - actor/ppo_kl:np.float64(0.003978899027885063) - actor/pg_clipfrac_lower:np.float64(5.031936325394781e-06) - actor/grad_norm:np.float64(0.07224454870447516) - perf/mfu/actor:np.float64(0.10882584469688641) - perf/max_memory_allocated_gb:np.float64(74.97313690185547) - perf/max_memory_reserved_gb:np.float64(81.984375) - perf/cpu_memory_used_gb:np.float64(154.65776443481445) - actor/lr:np.float64(0.0001) - training/global_step:22 - training/epoch:7 - critic/score/mean:0.13623046875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.13623046875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:1.008189620677058e-08 - critic/advantages/max:13.715760231018066 - critic/advantages/min:-18.613527297973633 - critic/returns/mean:0.032614242285490036 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.02294921875 - critic/values/max:1.234375 - critic/values/min:-0.25390625 - critic/vf_explained_var:0.8822654485702515 - response_length/mean:859.4638671875 - response_length/max:1024.0 - response_length/min:5.0 - response_length/clip_ratio:0.78955078125 - response_length_non_aborted/mean:859.4638671875 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:5.0 - response_length_non_aborted/clip_ratio:0.78955078125 - response/aborted_ratio:0.0 - prompt_length/mean:103.73681640625 - prompt_length/max:238.0 - prompt_length/min:63.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.0004337914288043976 - timing_s/generate_sequences:58.137855529785156 - timing_s/generation_timing/max:58.872962951660156 - timing_s/generation_timing/min:57.402748107910156 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:73.10305476561189 - timing_s/reward:0.6404705345630646 - timing_s/old_log_prob:29.59346951916814 - timing_s/values:42.6602391526103 - timing_s/adv:0.26576436311006546 - timing_s/update_critic:107.93877945840359 - timing_s/update_actor:103.26666911318898 - timing_s/step:357.5426509566605 - timing_s/stop_profile:9.19736921787262e-05 - timing_per_token_ms/values:0.021626017561591628 - timing_per_token_ms/gen:0.041531531833419434 - timing_per_token_ms/update_critic:0.05471806971811997 - timing_per_token_ms/adv:0.0001347255640856344 - timing_per_token_ms/update_actor:0.05234960806899856 - perf/total_num_tokens:1972635 - perf/time_per_step:357.5426509566605 - perf/throughput:2758.600959524564
[36m(WorkerDict pid=7191)[0m WARNING 10-22 05:58:00 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  73%|███████▎  | 22/30 [2:08:04<48:31, 363.88s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 06:03:57 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:23 - global_seqlen/min:986781 - global_seqlen/max:1032061 - global_seqlen/minmax_diff:45280 - global_seqlen/balanced_min:1009421 - global_seqlen/balanced_max:1009421 - global_seqlen/mean:1009421.0 - actor/entropy:7.658969402313232 - critic/vf_loss:np.float64(8.800726334357023e-05) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.024480517316220585) - critic/grad_norm:np.float64(0.12729694228619337) - perf/mfu/critic:np.float64(0.1131136840747782) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00015673104246616276) - actor/pg_clipfrac:np.float64(0.007414937552994161) - actor/ppo_kl:np.float64(0.00015827763741071976) - actor/pg_clipfrac_lower:np.float64(4.226563021347829e-06) - actor/grad_norm:np.float64(0.08083552215248346) - perf/mfu/actor:np.float64(0.11235341370607634) - perf/max_memory_allocated_gb:np.float64(74.97313690185547) - perf/max_memory_reserved_gb:np.float64(81.984375) - perf/cpu_memory_used_gb:np.float64(134.08283615112305) - actor/lr:np.float64(0.0001) - training/global_step:23 - training/epoch:7 - critic/score/mean:0.09765625 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.09765625 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-2.533478982158499e-10 - critic/advantages/max:15.161008834838867 - critic/advantages/min:-21.80044174194336 - critic/returns/mean:0.02157778851687908 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.01312255859375 - critic/values/max:1.25 - critic/values/min:-0.23046875 - critic/vf_explained_var:0.8684632182121277 - response_length/mean:882.2548828125 - response_length/max:1024.0 - response_length/min:1.0 - response_length/clip_ratio:0.8154296875 - response_length_non_aborted/mean:882.2548828125 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:1.0 - response_length_non_aborted/clip_ratio:0.8154296875 - response/aborted_ratio:0.0 - prompt_length/mean:103.5078125 - prompt_length/max:256.0 - prompt_length/min:62.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:6.281957030296326e-05 - timing_s/generate_sequences:59.600440979003906 - timing_s/generation_timing/max:59.64967727661133 - timing_s/generation_timing/min:59.551204681396484 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:74.19621420279145 - timing_s/reward:0.9531574361026287 - timing_s/old_log_prob:27.919155597686768 - timing_s/values:38.78485929965973 - timing_s/adv:0.2653190344572067 - timing_s/update_critic:101.72415352612734 - timing_s/update_actor:102.49311728030443 - timing_s/step:346.43636702001095 - timing_s/stop_profile:0.00019458681344985962 - timing_per_token_ms/values:0.019211438685969348 - timing_per_token_ms/gen:0.0410636664324432 - timing_per_token_ms/update_critic:0.05038737728169284 - timing_per_token_ms/adv:0.0001314213962544898 - timing_per_token_ms/update_actor:0.050768270761309915 - perf/total_num_tokens:2018842 - perf/time_per_step:346.43636702001095 - perf/throughput:2913.7270104835547
[36m(WorkerDict pid=7191)[0m WARNING 10-22 06:03:58 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  77%|███████▋  | 23/30 [2:13:51<41:50, 358.67s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 06:09:44 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:24 - global_seqlen/min:995798 - global_seqlen/max:1015790 - global_seqlen/minmax_diff:19992 - global_seqlen/balanced_min:1005794 - global_seqlen/balanced_max:1005794 - global_seqlen/mean:1005794.0 - actor/entropy:7.742041110992432 - critic/vf_loss:np.float64(6.706851023352556e-05) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.019981181465823283) - critic/grad_norm:np.float64(0.09871043590828776) - perf/mfu/critic:np.float64(0.10316565656377796) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0004485120118715713) - actor/pg_clipfrac:np.float64(0.00657865791470158) - actor/ppo_kl:np.float64(0.00041545126424580303) - actor/pg_clipfrac_lower:np.float64(1.8358682041252905e-06) - actor/grad_norm:np.float64(0.06171111995354295) - perf/mfu/actor:np.float64(0.11624678667096378) - perf/max_memory_allocated_gb:np.float64(74.97313690185547) - perf/max_memory_reserved_gb:np.float64(81.984375) - perf/cpu_memory_used_gb:np.float64(138.20808029174805) - actor/lr:np.float64(0.0001) - training/global_step:24 - training/epoch:7 - critic/score/mean:0.08154296875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.08154296875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:4.124237396041508e-09 - critic/advantages/max:18.116609573364258 - critic/advantages/min:-24.351774215698242 - critic/returns/mean:0.017987770959734917 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.01190185546875 - critic/values/max:1.1953125 - critic/values/min:-0.259765625 - critic/vf_explained_var:0.8812851905822754 - response_length/mean:878.87939453125 - response_length/max:1024.0 - response_length/min:2.0 - response_length/clip_ratio:0.82177734375 - response_length_non_aborted/mean:878.87939453125 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:2.0 - response_length_non_aborted/clip_ratio:0.82177734375 - response/aborted_ratio:0.0 - prompt_length/mean:103.34130859375 - prompt_length/max:217.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:5.805492401123047e-05 - timing_s/generate_sequences:58.981117248535156 - timing_s/generation_timing/max:61.746376037597656 - timing_s/generation_timing/min:56.21585464477539 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:78.18670193478465 - timing_s/reward:0.6621637605130672 - timing_s/old_log_prob:27.38808285817504 - timing_s/values:39.2332158125937 - timing_s/adv:0.24399155378341675 - timing_s/update_critic:111.17673051357269 - timing_s/update_actor:98.69024799391627 - timing_s/step:355.6426161117852 - timing_s/stop_profile:0.00019655749201774597 - timing_per_token_ms/values:0.01950360402457844 - timing_per_token_ms/gen:0.04343838391438885 - timing_per_token_ms/update_critic:0.055268141644100426 - timing_per_token_ms/adv:0.00012129300521946678 - timing_per_token_ms/update_actor:0.04906086534315987 - perf/total_num_tokens:2011588 - perf/time_per_step:355.6426161117852 - perf/throughput:2828.103141845802
[36m(WorkerDict pid=7191)[0m WARNING 10-22 06:09:47 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  80%|████████  | 24/30 [2:19:47<35:46, 357.80s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 06:15:45 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 25}
[36m(WorkerDict pid=7191)[0m WARNING 10-22 06:15:45 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(WorkerDict pid=7191)[0m WARNING 10-22 06:21:31 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m validation generation end
[36m(WorkerDict pid=7192)[0m WARNING 10-22 06:21:33 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m [prompt] system
[36m(TaskRunner pid=6616)[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
[36m(TaskRunner pid=6616)[0m user
[36m(TaskRunner pid=6616)[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after "####".
[36m(TaskRunner pid=6616)[0m assistant
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m [response] To determine how much Janet makes every day at the farmers' market, we need to follow these steps:
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 1. Calculate the number of eggs laid per day.
[36m(TaskRunner pid=6616)[0m 2. Determine the number of eggs that are eaten.
[36m(TaskRunner pid=6616)[0m 3. Determine the number of eggs that are used to bake muffins.
[36m(TaskRunner pid=6616)[0m 4. Determine the number of eggs that are sold.
[36m(TaskRunner pid=6616)[0m 5. Determine the amount of money made from the eggs sold.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m 1. The number of eggs laid per day is 16.
[36m(TaskRunner pid=6616)[0m 2. The number of eggs that are eaten is 3.
[36m(TaskRunner pid=6616)[0m 3. The number of eggs that are used to bake muffins is 4.
[36m(TaskRunner pid=6616)[0m 4. The number of eggs that are sold is 16 - 3 - 4 = 9.
[36m(TaskRunner pid=6616)[0m 5. The amount of money made from the eggs sold is 9 * 2 = 18.
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m Therefore, the answer is 18.#### 18
[36m(TaskRunner pid=6616)[0m [ground_truth] 18
[36m(TaskRunner pid=6616)[0m [score] 1.0
[36m(TaskRunner pid=6616)[0m step:25 - global_seqlen/min:997159 - global_seqlen/max:1005390 - global_seqlen/minmax_diff:8231 - global_seqlen/balanced_min:1001274 - global_seqlen/balanced_max:1001275 - global_seqlen/mean:1001274.5 - actor/entropy:8.26028060913086 - critic/vf_loss:np.float64(7.12098866486599e-05) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.018487732667985313) - critic/grad_norm:np.float64(0.040825347910868004) - perf/mfu/critic:np.float64(0.11419651033853945) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00019241567602534815) - actor/pg_clipfrac:np.float64(0.00896464125133889) - actor/ppo_kl:np.float64(0.0012380974131644962) - actor/pg_clipfrac_lower:np.float64(8.741602869122289e-06) - actor/grad_norm:np.float64(0.06534036342054605) - perf/mfu/actor:np.float64(0.1125857818123962) - perf/max_memory_allocated_gb:np.float64(74.97313690185547) - perf/max_memory_reserved_gb:np.float64(81.984375) - perf/cpu_memory_used_gb:np.float64(138.31138229370117) - actor/lr:np.float64(0.0001) - val-core/openai/gsm8k/reward/mean@1:np.float64(0.5382865807429871) - training/global_step:25 - training/epoch:8 - critic/score/mean:0.07763671875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.07763671875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-2.0933077493623387e-09 - critic/advantages/max:18.390466690063477 - critic/advantages/min:-23.703004837036133 - critic/returns/mean:0.016895515844225883 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.01446533203125 - critic/values/max:1.1953125 - critic/values/min:-0.248046875 - critic/vf_explained_var:0.8657571077346802 - response_length/mean:873.79296875 - response_length/max:1024.0 - response_length/min:4.0 - response_length/clip_ratio:0.80908203125 - response_length_non_aborted/mean:873.79296875 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.80908203125 - response/aborted_ratio:0.0 - prompt_length/mean:104.01416015625 - prompt_length/max:222.0 - prompt_length/min:62.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.0004622451961040497 - timing_s/generate_sequences:59.430686950683594 - timing_s/generation_timing/max:60.31039810180664 - timing_s/generation_timing/min:58.55097579956055 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:75.6638573743403 - timing_s/reward:0.634528074413538 - timing_s/old_log_prob:27.49922913312912 - timing_s/values:38.89944304525852 - timing_s/adv:0.37604494392871857 - timing_s/update_critic:100.03573520854115 - timing_s/update_actor:101.42472058907151 - timing_s/step:344.62881207466125 - timing_s/testing:40.52300501987338 - timing_s/stop_profile:8.853152394294739e-05 - timing_per_token_ms/values:0.019424964405494457 - timing_per_token_ms/gen:0.042281460460155025 - timing_per_token_ms/update_critic:0.049954200975127774 - timing_per_token_ms/adv:0.00018778314234943493 - timing_per_token_ms/update_actor:0.05064780966112266 - perf/total_num_tokens:2002549 - perf/time_per_step:344.62881207466125 - perf/throughput:2905.370836443824
[36m(TaskRunner pid=6616)[0m 
Training Progress:  83%|████████▎ | 25/30 [2:26:15<30:34, 367.00s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 06:22:09 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:26 - global_seqlen/min:992265 - global_seqlen/max:1006760 - global_seqlen/minmax_diff:14495 - global_seqlen/balanced_min:999512 - global_seqlen/balanced_max:999513 - global_seqlen/mean:999512.5 - actor/entropy:7.697845458984375 - critic/vf_loss:np.float64(7.495265440127241e-05) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.013364011221142391) - critic/grad_norm:np.float64(0.056857381481677294) - perf/mfu/critic:np.float64(0.11381527412500064) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00011762911803181453) - actor/pg_clipfrac:np.float64(0.024669408251611458) - actor/ppo_kl:np.float64(0.004036318823196439) - actor/pg_clipfrac_lower:np.float64(1.0512885921798443e-05) - actor/grad_norm:np.float64(0.12265280028805137) - perf/mfu/actor:np.float64(0.11221373644198974) - perf/max_memory_allocated_gb:np.float64(74.97313690185547) - perf/max_memory_reserved_gb:np.float64(81.984375) - perf/cpu_memory_used_gb:np.float64(135.74888229370117) - actor/lr:np.float64(0.0001) - training/global_step:26 - training/epoch:8 - critic/score/mean:0.0546875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.0546875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:9.256098110199673e-09 - critic/advantages/max:17.095022201538086 - critic/advantages/min:-22.795429229736328 - critic/returns/mean:0.011481337249279022 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.01422119140625 - critic/values/max:1.234375 - critic/values/min:-0.2060546875 - critic/vf_explained_var:0.7866344451904297 - response_length/mean:872.55224609375 - response_length/max:1024.0 - response_length/min:3.0 - response_length/clip_ratio:0.8154296875 - response_length_non_aborted/mean:872.55224609375 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.8154296875 - response/aborted_ratio:0.0 - prompt_length/mean:103.5341796875 - prompt_length/max:238.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.0001039654016494751 - timing_s/generate_sequences:59.91408157348633 - timing_s/generation_timing/max:60.002105712890625 - timing_s/generation_timing/min:59.82605743408203 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:74.05101250112057 - timing_s/reward:0.6229934990406036 - timing_s/old_log_prob:26.920603025704622 - timing_s/values:38.080323215574026 - timing_s/adv:0.22480721771717072 - timing_s/update_critic:100.1836321465671 - timing_s/update_actor:101.56679695099592 - timing_s/step:341.70430620387197 - timing_s/stop_profile:0.000207412987947464 - timing_per_token_ms/values:0.019049448213791235 - timing_per_token_ms/gen:0.041439032573331855 - timing_per_token_ms/update_critic:0.05011624774405878 - timing_per_token_ms/adv:0.00011245843234435323 - timing_per_token_ms/update_actor:0.05080816745713331 - perf/total_num_tokens:1999025 - perf/time_per_step:341.70430620387197 - perf/throughput:2925.080199029327
[36m(WorkerDict pid=7191)[0m WARNING 10-22 06:22:09 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  87%|████████▋ | 26/30 [2:31:57<23:57, 359.46s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 06:27:52 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:27 - global_seqlen/min:996724 - global_seqlen/max:1003608 - global_seqlen/minmax_diff:6884 - global_seqlen/balanced_min:1000166 - global_seqlen/balanced_max:1000166 - global_seqlen/mean:1000166.0 - actor/entropy:7.305500507354736 - critic/vf_loss:np.float64(0.00010124658487598026) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.006070703822523171) - critic/grad_norm:np.float64(0.04071713634766638) - perf/mfu/critic:np.float64(0.10628761522059507) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-7.243003616963506e-05) - actor/pg_clipfrac:np.float64(0.01320555658048761) - actor/ppo_kl:np.float64(0.006411222097945313) - actor/pg_clipfrac_lower:np.float64(1.4482729795872729e-05) - actor/grad_norm:np.float64(0.0896248840726912) - perf/mfu/actor:np.float64(0.10667475197641432) - perf/max_memory_allocated_gb:np.float64(74.97313690185547) - perf/max_memory_reserved_gb:np.float64(81.984375) - perf/cpu_memory_used_gb:np.float64(137.29927444458008) - actor/lr:np.float64(0.0001) - training/global_step:27 - training/epoch:8 - critic/score/mean:0.0244140625 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.0244140625 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-4.811476994603936e-09 - critic/advantages/max:15.069531440734863 - critic/advantages/min:-18.604196548461914 - critic/returns/mean:0.004776278510689735 - critic/returns/max:1.0 - critic/returns/min:0.0 - critic/values/mean:0.0062255859375 - critic/values/max:1.1328125 - critic/values/min:-0.23046875 - critic/vf_explained_var:0.2554693818092346 - response_length/mean:873.35498046875 - response_length/max:1024.0 - response_length/min:2.0 - response_length/clip_ratio:0.8212890625 - response_length_non_aborted/mean:873.35498046875 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:2.0 - response_length_non_aborted/clip_ratio:0.8212890625 - response/aborted_ratio:0.0 - prompt_length/mean:103.36962890625 - prompt_length/max:217.0 - prompt_length/min:56.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:6.47418200969696e-05 - timing_s/generate_sequences:60.32469940185547 - timing_s/generation_timing/max:61.10545349121094 - timing_s/generation_timing/min:59.543949127197266 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:76.82036525011063 - timing_s/reward:0.9649732634425163 - timing_s/old_log_prob:27.067399363964796 - timing_s/values:40.16848332434893 - timing_s/adv:0.2537994347512722 - timing_s/update_critic:107.3109124712646 - timing_s/update_actor:106.85400491580367 - timing_s/step:359.52115251868963 - timing_s/stop_profile:7.8544020652771e-05 - timing_per_token_ms/values:0.02008090823140805 - timing_per_token_ms/gen:0.04294925294826637 - timing_per_token_ms/update_critic:0.053646550908181545 - timing_per_token_ms/adv:0.00012687865551881997 - timing_per_token_ms/update_actor:0.05341813504748395 - perf/total_num_tokens:2000332 - perf/time_per_step:359.52115251868963 - perf/throughput:2781.9392349884242
[36m(WorkerDict pid=7192)[0m WARNING 10-22 06:27:53 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  90%|█████████ | 27/30 [2:37:57<17:58, 359.51s/it]
[36m(WorkerDict pid=7192)[0m WARNING 10-22 06:33:53 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:28 - global_seqlen/min:991272 - global_seqlen/max:1007203 - global_seqlen/minmax_diff:15931 - global_seqlen/balanced_min:999237 - global_seqlen/balanced_max:999238 - global_seqlen/mean:999237.5 - actor/entropy:7.571019172668457 - critic/vf_loss:np.float64(2.157907474042986e-05) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(-0.00031206096376212855) - critic/grad_norm:np.float64(0.050797575153410435) - perf/mfu/critic:np.float64(0.09096066152694242) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.0002180577457195909) - actor/pg_clipfrac:np.float64(0.016787056184909943) - actor/ppo_kl:np.float64(0.006325624230498761) - actor/pg_clipfrac_lower:np.float64(5.394628033172921e-07) - actor/grad_norm:np.float64(0.0817703939974308) - perf/mfu/actor:np.float64(0.10653022391097142) - perf/max_memory_allocated_gb:np.float64(74.98045921325684) - perf/max_memory_reserved_gb:np.float64(81.984375) - perf/cpu_memory_used_gb:np.float64(111.6413345336914) - actor/lr:np.float64(0.0001) - training/global_step:28 - training/epoch:9 - critic/score/mean:0.0 - critic/score/max:0.0 - critic/score/min:0.0 - critic/rewards/mean:0.0 - critic/rewards/max:0.0 - critic/rewards/min:0.0 - critic/advantages/mean:-6.12012085454694e-09 - critic/advantages/max:9.470999717712402 - critic/advantages/min:-21.363433837890625 - critic/returns/mean:0.0 - critic/returns/max:0.0 - critic/returns/min:0.0 - critic/values/mean:-0.0022430419921875 - critic/values/max:0.57421875 - critic/values/min:-0.2578125 - critic/vf_explained_var:-71.81172180175781 - response_length/mean:872.2607421875 - response_length/max:1024.0 - response_length/min:2.0 - response_length/clip_ratio:0.81396484375 - response_length_non_aborted/mean:872.2607421875 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:2.0 - response_length_non_aborted/clip_ratio:0.81396484375 - response/aborted_ratio:0.0 - prompt_length/mean:103.55712890625 - prompt_length/max:238.0 - prompt_length/min:63.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.00043070316314697266 - timing_s/generate_sequences:59.782081604003906 - timing_s/generation_timing/max:61.489688873291016 - timing_s/generation_timing/min:58.0744743347168 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:75.3776468001306 - timing_s/reward:0.9866898395121098 - timing_s/old_log_prob:33.087690498679876 - timing_s/values:41.173243440687656 - timing_s/adv:0.3443201035261154 - timing_s/update_critic:125.25371677428484 - timing_s/update_actor:106.9703432135284 - timing_s/step:383.3049355484545 - timing_s/stop_profile:5.451962351799011e-05 - timing_per_token_ms/values:0.020602330997729595 - timing_per_token_ms/gen:0.04219551542503631 - timing_per_token_ms/update_critic:0.06267464780609457 - timing_per_token_ms/adv:0.00017229142397383776 - timing_per_token_ms/update_actor:0.05352598517045667 - perf/total_num_tokens:1998475 - perf/time_per_step:383.3049355484545 - perf/throughput:2606.899643935537
[36m(WorkerDict pid=7191)[0m WARNING 10-22 06:33:53 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  93%|█████████▎| 28/30 [2:44:23<12:15, 367.55s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 06:40:17 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m step:29 - global_seqlen/min:980579 - global_seqlen/max:1002134 - global_seqlen/minmax_diff:21555 - global_seqlen/balanced_min:991356 - global_seqlen/balanced_max:991357 - global_seqlen/mean:991356.5 - actor/entropy:6.875364780426025 - critic/vf_loss:np.float64(1.890157645689783e-05) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(-0.00034398121860590436) - critic/grad_norm:np.float64(0.03109214425785467) - perf/mfu/critic:np.float64(0.08426486684265526) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(-0.00012262981226740521) - actor/pg_clipfrac:np.float64(0.028171866377761035) - actor/ppo_kl:np.float64(0.004336235870255223) - actor/pg_clipfrac_lower:np.float64(4.76837158203125e-07) - actor/grad_norm:np.float64(0.1880055139772594) - perf/mfu/actor:np.float64(0.10538859268599303) - perf/max_memory_allocated_gb:np.float64(74.98045921325684) - perf/max_memory_reserved_gb:np.float64(82.009765625) - perf/cpu_memory_used_gb:np.float64(158.08584785461426) - actor/lr:np.float64(0.0001) - training/global_step:29 - training/epoch:9 - critic/score/mean:0.0 - critic/score/max:0.0 - critic/score/min:0.0 - critic/rewards/mean:0.0 - critic/rewards/max:0.0 - critic/rewards/min:0.0 - critic/advantages/mean:7.454372230597528e-09 - critic/advantages/max:10.250934600830078 - critic/advantages/min:-15.964332580566406 - critic/returns/mean:0.0 - critic/returns/max:0.0 - critic/returns/min:0.0 - critic/values/mean:-0.0035858154296875 - critic/values/max:0.3984375 - critic/values/min:-0.26171875 - critic/vf_explained_var:-62.4129638671875 - response_length/mean:863.560546875 - response_length/max:1024.0 - response_length/min:2.0 - response_length/clip_ratio:0.79736328125 - response_length_non_aborted/mean:863.560546875 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:2.0 - response_length_non_aborted/clip_ratio:0.79736328125 - response/aborted_ratio:0.0 - prompt_length/mean:104.56103515625 - prompt_length/max:256.0 - prompt_length/min:56.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:5.04031777381897e-05 - timing_s/generate_sequences:58.474205017089844 - timing_s/generation_timing/max:60.66697311401367 - timing_s/generation_timing/min:56.281436920166016 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:75.6833786405623 - timing_s/reward:0.6220175474882126 - timing_s/old_log_prob:29.45288023725152 - timing_s/values:41.433938421308994 - timing_s/adv:0.23198506608605385 - timing_s/update_critic:133.93072487786412 - timing_s/update_actor:107.20759038627148 - timing_s/step:388.63550774753094 - timing_s/stop_profile:7.812678813934326e-05 - timing_per_token_ms/values:0.02089759759547095 - timing_per_token_ms/gen:0.042793495905488886 - timing_per_token_ms/update_critic:0.06754922415794122 - timing_per_token_ms/adv:0.00011700385587125007 - timing_per_token_ms/update_actor:0.05407115925818385 - perf/total_num_tokens:1982713 - perf/time_per_step:388.63550774753094 - perf/throughput:2550.8644481451097
[36m(WorkerDict pid=7192)[0m WARNING 10-22 06:40:18 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m 
Training Progress:  97%|█████████▋| 29/30 [2:50:52<06:13, 373.91s/it]
[36m(WorkerDict pid=7191)[0m WARNING 10-22 06:46:46 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': False, 'validate': True, 'global_steps': 30}
[36m(WorkerDict pid=7192)[0m WARNING 10-22 06:46:47 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(WorkerDict pid=7191)[0m WARNING 10-22 06:53:09 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m validation generation end
[36m(WorkerDict pid=7192)[0m WARNING 10-22 06:53:10 [tokenizer.py:284] No tokenizer found in /simon-stub-path, using base model tokenizer instead. (Exception: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '/simon-stub-path'.)
[36m(TaskRunner pid=6616)[0m [prompt] system
[36m(TaskRunner pid=6616)[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
[36m(TaskRunner pid=6616)[0m user
[36m(TaskRunner pid=6616)[0m Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Let's think step by step and output the final answer after "####".
[36m(TaskRunner pid=6616)[0m assistant
[36m(TaskRunner pid=6616)[0m 
[36m(TaskRunner pid=6616)[0m [response] To determine how much in dollars Janet makes every day at the farmers' market, we need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs she has available to sell. We need to determine how many eggs
[36m(TaskRunner pid=6616)[0m [ground_truth] 18
[36m(TaskRunner pid=6616)[0m [score] 0.0
[36m(TaskRunner pid=6616)[0m local_global_step_folder: checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 06:53:50,936:[Rank 1] Saved model to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/actor/model_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 06:53:51,042:[Rank 1] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/actor/optim_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 06:53:51,043:[Rank 1] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/actor/extra_state_world_size_2_rank_1.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 06:53:52,182:[Rank 0] Saved model config and tokenizer class to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/actor/huggingface
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 06:54:07,870:[Rank 0] Saved model to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/critic/model_world_size_2_rank_0.pt[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 06:53:51,787:[Rank 0] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/actor/optim_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 06:53:51,788:[Rank 0] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/actor/extra_state_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 06:54:07,963:[Rank 0] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/critic/optim_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 06:54:07,964:[Rank 0] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/critic/extra_state_world_size_2_rank_0.pt
[36m(WorkerDict pid=7191)[0m INFO:2025-10-22 06:54:08,102:[Rank 0] Saved model config and tokenizer class to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/critic/huggingface
[36m(TaskRunner pid=6616)[0m step:30 - global_seqlen/min:952280 - global_seqlen/max:985365 - global_seqlen/minmax_diff:33085 - global_seqlen/balanced_min:968822 - global_seqlen/balanced_max:968823 - global_seqlen/mean:968822.5 - actor/entropy:8.225940704345703 - critic/vf_loss:np.float64(1.567704483562693e-05) - critic/vf_clipfrac:np.float64(0.0) - critic/vpred_mean:np.float64(0.0003437716849195027) - critic/grad_norm:np.float64(0.028652243898250163) - perf/mfu/critic:np.float64(0.09533264577014573) - critic/lr:np.float64(0.0001) - actor/pg_loss:np.float64(2.5876666370550083e-05) - actor/pg_clipfrac:np.float64(0.027055792735495743) - actor/ppo_kl:np.float64(0.005243064037514955) - actor/pg_clipfrac_lower:np.float64(5.280857067191391e-07) - actor/grad_norm:np.float64(0.2180509027093649) - perf/mfu/actor:np.float64(0.09488552870830075) - perf/max_memory_allocated_gb:np.float64(74.98045921325684) - perf/max_memory_reserved_gb:np.float64(82.009765625) - perf/cpu_memory_used_gb:np.float64(163.01925659179688) - actor/lr:np.float64(0.0001) - val-core/openai/gsm8k/reward/mean@1:np.float64(0.1607278241091736) - training/global_step:30 - training/epoch:9 - critic/score/mean:0.0 - critic/score/max:0.0 - critic/score/min:0.0 - critic/rewards/mean:0.0 - critic/rewards/max:0.0 - critic/rewards/min:0.0 - critic/advantages/mean:7.320717365644214e-09 - critic/advantages/max:7.345722675323486 - critic/advantages/min:-10.966876029968262 - critic/returns/mean:0.0 - critic/returns/max:0.0 - critic/returns/min:0.0 - critic/values/mean:-0.000308990478515625 - critic/values/max:0.25 - critic/values/min:-0.16796875 - critic/vf_explained_var:-51.09299850463867 - response_length/mean:842.68798828125 - response_length/max:1024.0 - response_length/min:3.0 - response_length/clip_ratio:0.763671875 - response_length_non_aborted/mean:842.68798828125 - response_length_non_aborted/max:1024.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.763671875 - response/aborted_ratio:0.0 - prompt_length/mean:103.427734375 - prompt_length/max:216.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:6.2599778175354e-05 - timing_s/generate_sequences:59.861778259277344 - timing_s/generation_timing/max:61.06689453125 - timing_s/generation_timing/min:58.65666580200195 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:76.59179159626365 - timing_s/reward:0.6522529795765877 - timing_s/old_log_prob:28.814764942973852 - timing_s/values:44.96881026029587 - timing_s/adv:0.2309761680662632 - timing_s/update_critic:115.70529145002365 - timing_s/update_actor:116.26312402263284 - timing_s/step:383.2930189855397 - timing_s/testing:50.136461567133665 - timing_s/save_checkpoint:22.144160497933626 - timing_s/stop_profile:0.00010252371430397034 - timing_per_token_ms/values:0.023207971666789257 - timing_per_token_ms/gen:0.044379813478344354 - timing_per_token_ms/update_critic:0.05971439115525478 - timing_per_token_ms/adv:0.00011920458498138886 - timing_per_token_ms/update_actor:0.06000228319564876 - perf/total_num_tokens:1937645 - perf/time_per_step:383.2930189855397 - perf/throughput:2527.6288688068967
[36m(TaskRunner pid=6616)[0m ("Final validation metrics: {'val-core/openai/gsm8k/reward/mean@1': "
[36m(TaskRunner pid=6616)[0m  'np.float64(0.1607278241091736)}')
[36m(TaskRunner pid=6616)[0m 
Training Progress: 100%|██████████| 30/30 [2:58:27<00:00, 398.45s/it]
Training Progress: 100%|██████████| 30/30 [2:58:27<00:00, 356.93s/it]
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 06:54:08,461:[Rank 1] Saved model to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/critic/model_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 06:54:08,555:[Rank 1] Saved optim to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/critic/optim_world_size_2_rank_1.pt
[36m(WorkerDict pid=7192)[0m INFO:2025-10-22 06:54:08,556:[Rank 1] Saved extra_state to /workspace/rl_cot_monitorability/scripts/checkpoints/verl_gsm8k_ppo_qwen1.5B/qwen1.5b_kl0.01_20251022_035201/global_step_30/critic/extra_state_world_size_2_rank_1.pt
